python -m pip install --upgrade pip

pip install scipy
pip install scikit-learn
pip install scikit-image   -----> skimage
pip install Pillow   ----> PIL
pip install opencv-python    --- cv2
pip install matplotlib

> pip cache dir    ----> cache dir 확인  ----> pip cache purge
> pip cache purge  ---> to clear all files from pip's cache.   ----> C:\Users\BRAIN\AppData\Local\pip\cache는 안 지워지네...
> conda clean --all


### conda activate  
> source ~/anaconda3/etc/profile.d/conda.sh


conda --version


conda config --describe
conda config --set auto_activate_base true   conda 4.6 이상




=======
C:\Users\Administrator\AppData\Local\pip    ----> pip cache directory    > cd %USERPROFILE%\AppData\Local\pip   ---> pip cache purge로 안지워지네~~
========
python 3.6설치

https://repo.continuum.io/archive/index.html
Anaconda3-5.2.0-Windows-x86_64.exe  ---> python 3.6

python 버전 upgrade: > conda install python==3.6.8  (<--- 3.6.4에서 upgrade 된다)
=============================
pydev 수동 설치:
- features와 plugins 파일들을 위치에 복사한다.
- java는 설치해도 되지만, eclipse아래에 jre디렉토리 만들고, 복사해도 
- eclipse 실행 후, windows-preferences-PyDev-Interpreters-Python Interpreter - QuickAuto-Config

===========================================================================
conda info   ---> cache 디렉토리 확인

conda clean --all

===========================================================================
> conda create -n xxx python=3.6    ----> pythn 버전이 반드시 명시되어야 한다. 없으면, 디폴트로 만들지 않는다.
> conda env list --> 설치된 env 확인
> concda remove --name xxx --all   ---> 제거하기
===========================================================================
venv로 가상환경 만들기

1. 가상환경을 만들 디렉토리를 만들어 이동한다.
2. python -m venv 가상환경이름   --> 현재 디렉토리 아래에 가상환경 이름을 가진 directory가 만들어진다.
3. 가상환경이 만들어지 directory로 이동한다.
4. xxxx>     Scripts\activate
5. 종료하려면, deactivate  또는 conda deactivate
=====================================================================
eclipse: Windows-Preference-PyDev-Interpreters-Python Interpreter  ---> 복수로 등록 가능
예: 
python     C:\Anaconda\python.exe
tfcpu      C:\Anaconda\hccho-virtual\tfcpu\Scripts\python.exe

이렇게 등록한 2개는 각각의 project에서 선택가능하다.  project의 properties - PyDev-Interpreter/Grammar - Interpreter 에서 선택하면 된다.

=====================================================================
https://github.com/higgsfield/RL-Adventure/blob/master/6.categorical%20dqn.ipynb  ---> 이 파일을 colab에서 열기.  nbviewer에서 열기.

https://nbviewer.jupyter.org/github//higgsfield/RL-Adventure/blob/master/6.categorical%20dqn.ipynb

https://colab.research.google.com/github//higgsfield/RL-Adventure/blob/master/6.categorical%20dqn.ipynb

=====================================================================

> pip download 
=====================================================================
import skimage.io as io   --- error --- pip install로는 안되고,
pip install --upgrade scikit-image
=====================================================================
python package 관리자 권한 설치
>pip install box2d-py   -----> Consider using the `--user` option or check the permissions.
>python -m pip install --user box2d-py

=====================================================================
Eclipse에 이미 만들어져 있는 project 추가: New -> Project -> General -> Project --> 폴더 선택 & 이름 입력

=============================

import sys
sys.path.append("../")   <--- 코드내에 추가
sys.path.append("D:\\hccho\\im2txt\\im2txt")

sys.path.insert(0,'D:\\hccho\\ML\\PythonCode\\StackGAN-master')  <--- 코드내에 추가
또는 eclipse project properties에서 Resource-Linked Resources에서 path를 등록하면 
=====================================================================
방법은 단순합니다.

- cuda 9.0 + cudnn 7.1 + tensorflow 1.8
- cuda 8.1 + cudnn 6.0 + tensorflow 1.3

(cuda 8.0 다운받으러 가면, 8.0은 없고 8.1만 있음)

일단 
- cuda 9.0 + cudnn 7.1 설치 -> C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0
- cuda 8.1 + cudnn 6.0 설치 -> C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0

설치 후, 환경변수 path에 2개 디렉토리 모두 등록

base에 tensorflow-gpu 1.8 설치, 가상환경(저는 venv사용)에 tensorflow-gpu 1.3 설치

이렇게 하면 2가지 모두 잘 작동합니다.

===================================================================
spyder kernel 죽은 문제 해결
os.environ['KMP_DUPLICATE_LIB_OK']='True'


=====================================================================


num_batch = int(max_train/batch_size) # 1epoch에 필요한 반복

for i in range(num_epoch):
    for j in range(num_batch):
	.
	.
	.
        if j % show_every== 0:
            print('(Iteration %d / %d, Epoch %d / %d) loss: %f' % (i*num_batch+j, num_epoch*num_batch, i, num_epoch, loss_xxx)

=====================================================================

np.set_printoptions(threshold=sys.maxsize)  <--- 모든 data 다 표시
np.set_printoptions(precision=4)  <--- 유효숫자 표시
np.set_printoptions(suppress=True) <----- e없이 표시

np.set_printoptions(suppress=True, formatter={'float_kind':'{:5.3f}'.format}, linewidth=130)
====================================================================
import ctypes  # An included library with Python install.
def Mbox(title, text, style):
    ctypes.windll.user32.MessageBoxW(0, text, title, style)
====================================================================
np.shape ==> (n1-axis=0,n2-axis=1,n3-axis=2,...)
np.sum(x, axis=n) ==>  axis n 이 없으짐
===================================================================
np.squeeze(x) <== Remove single-dimensional entries from the shape of an array
np.expand_dims <== Insert a new axis, corresponding to a given position in the array shape
===================================================================
a=[1,1,2,2]
a= list(map((lambda x: x*x),a))
===================================================================
a=np.array([1,2,3,4,5,4,3,2,10]
b = a[a<5]  # numpy array이기 때문에 가능

# list comprehension
a=[1,2,3,4,5,4,3,2,10]
b = [ x*10 for x in a if x< 5]

y = [-1 if a==0 else 1 for a in y]
z = [-1 for a in y if a==1]

# 이중 list comprehesion
matrix = [[1,2,3],[4,5,6]]
a = [x for row in maxtrix for x in row]


================================================
x = np.arange(-2, 3)
x.ravel()[np.flatnonzero(x)]  # Use the indices of the non-zero elements as an index array to extract these elements:
===================================================================
# sting ==> float변환
a = [['1.2','2.33'],['1.2','2.33']]
b = np.array(a,dtype=np.float32)

# numpy array ==> list
c = b.tolist()
===================================================================
A[[0,1,2],[0,0,1]] = [1,2,7]   #numpy array A[0,0],A[1,0],A[2,1]에 각각 1,2,7


===================================================================
# singular value of a ~ sqrt(eigenvalue) of (a.T)a  or a(a.T)
# data matrix a의 평균을 0으로 맞추고 나면, SVD는 PCA의 일반화. 
# SVD는 a.T.dot(a)를 계산하는 과정에서의 수치적인 손실을 줄일 수 있어 더 안정적이다.



# np.linalg의 첫번째  return  U의 열vector가 eigenvector에 해당함.

import contextlib

@contextlib.contextmanager
def printoptions(*args, **kwargs):
    original = np.get_printoptions()
    np.set_printoptions(*args, **kwargs)
    try:
        yield
    finally: 
        np.set_printoptions(**original)


import numpy as np
np.set_printoptions(threshold=np.nan)
#a = np.random.randint(10, size=(9, 6))
a =np.array([[0, 9, 7, 9, 1, 6, 7],
       [2, 3, 7, 8, 9, 6, 15],
       [2, 3, 4, 5, 9, 4, 13],
       [5, 8, 0, 3, 9, 5, 14],
       [7, 9, 9, 8, 4, 1, 5],
       [2, 7, 8, 2, 0, 0, 0],
       [8, 7, 0, 4, 8, 3, 12],
       [9, 2, 3, 8, 3, 0, 3],
       [6, 6, 2, 0, 9, 0, 9]])


#a =np.array([[5,-7,7],[4,-3,4],[4,-1,2]])
aa = a.T.dot(a)  # covariance matrix of a
w,z = np.linalg.eig(aa)  # z의 열벡터가 eigenvector

bb = a.dot(a.T)
ww,zz = np.linalg.eig(bb)  # zz의 열벡터가 eigenvector

U, s, V = np.linalg.svd(a, full_matrices=True) # V의 행벡터가 aa의 eigenvector. vector들 간의 부호가 뒤죽박죽.
# V의 행벡터가 aa의 eigenvector. vector들 간의 부호가 뒤죽박죽. 즉 z.T ~ V, 행들의 부호 때문에 잘 봐야함. rank 갯수 까지만 유효
# U의 열벡터가 bb의 eigenvector. zz.T ~ U.T. rank 갯수까지 유효


UU, ss, VV = np.linalg.svd(a, full_matrices=False) # "numerical recipes" 는 False에 해당하는 것을 구현

print(U.shape,s.shape,V.shape)
print(UU.shape,ss.shape,VV.shape)



with printoptions(precision=3, suppress=True):
    
    
    # spectral decomposition은 eigenvalue의 정의에 의해 쉽게 증명가능
    print('eigen decomposition = spectral decomposition', z.dot(np.diag(w)).dot(z.T) - aa)  
    
    # enginvalue 비교
    print('eigenvalue 비교',np.sqrt(w) - s)
    print('U.dot(U.T)',U.dot(U.T))
    print('UU.dot(UU.T)',UU.dot(UU.T))   # Identity 안됨
    print('UU.T.dot(UU)',UU.T.dot(UU))
    print('V.dot(V.T)', V.dot(V.T))
    print('VV.dot(VV.T)', VV.dot(VV.T))
    
    # full matrix는 padding을 해야 복원
    print(U.dot(np.pad(np.diag(s),[(0,2),(0,0)],'constant')).dot(V))
    # reduced form에서는 그냥 곱하면 됨
    print(UU.dot(np.diag(ss)).dot(VV))
    
    
    r = np.min(a.shape)
    print('thin SVD')
    print(U[:,:r].dot(np.diag(s[:r])).dot(V[:r,:]))
    print(UU[:,:r].dot(np.diag(ss[:r])).dot(VV[:r,:]))   
    
    
    # rank을 이용하여 ...
    r= np.linalg.matrix_rank(a)
    print('compact SVD')
    print(U[:,:r].dot(np.diag(s[:r])).dot(V[:r,:]))
    print(UU[:,:r].dot(np.diag(ss[:r])).dot(VV[:r,:]))
    
    
    r = 5 # rank 보다 작게 잡아, demension reduction을 할 수 있다.
    print('truncated SVD')
    print(U[:,:r].dot(np.diag(s[:r])).dot(V[:r,:]))
    print(UU[:,:r].dot(np.diag(ss[:r])).dot(VV[:r,:]))    

    # 행 축소
    r=4
    print('row reduction')
    print(U[:,:r].T.dot(a))

    # 열 축소
    r=3
    print('col reduction')
    print(a.dot(V[:r,:].T))

    
=====================================================================================
def f(x):
    return x+10

# make another list from a list
A = [1,2,3,4]
A2=[[1,2],[3,4],[5,6]]
#B = [x*10 for x in A]
#B = [f(x) for x in A]

#B = list(map(lambda x: x*10,A))
B = list(map(f,A))

df = pd.DataFrame(A2, columns=['age','age2'])
df['age']= df['age'].apply(f)
=====================================================================================
# DataFrame은 dict형으로 만들거나,  List에서 칼럼명을 지정해서 만들 수 있다.
df = pd.DataFrame({'Name':['C','K','P'],'age':[34,53,25]})


A=[[2,3,4],[3,3,5],[5,63,4],[3,4,5]]
A1=['a1','a2','a3']
A2=['x1','x2','x3','x4']
df2=pd.DataFrame(data=A,index=A2,columns=A1)

df3 = df2[['a3','a2']]  # 일부 칼럼만 가져오기
df3.columns = ['XX1','XX2']


======================
A = np.array([[13,24,3],[10,20,10],[100,1,1]])
print(A)
df2 = pd.DataFrame(A[1:,1:],columns=A[0,1:],index =A[1:,0])
print(df2)

=====================

모든 data출력
pandas.set_option('display.max_columns', None,'display.max_rows', None)

#Pivot
mydatapd = pd.DataFrame(mydata,columns=['A','B','C'])
mydatapd = mydatapd.pivot(index ='A',columns='B',values='C')

=====================================================================================
import pickle  # from six.moves import cPickle as pickle 도 가능
var1 = xxx
var2 = xxx
var3 = xx

with open('test.txt','wb') as f:
	pickle.dump(var1,f)
	pickle.dump(var2,f)
	pickle.dump(var3,f)



덤프(dump)한 순서대로 로드(load)된다.
 
with open('test.txt','rb') as f:
	data1=pickle.load(f)
	data2=pickle.load(f)
	data3=pickle.load(f)
=====================================================================================
with open('class_info.pickle','rb') as f:
	data1=pickle.load(f,encoding='latin1')
=====================================================================================
dict형으로 변수들을 묶어서 한번에 쓰고, 한번에 읽어올수 있다.
파일을 열때 'b'(binary)로 해야함.
with open('data.pickle', 'wb') as f:
    pickle.dump(data, f)

with open('data.pickle','rb') as f:
    data1=pickle.load(f)
=====================================================================================
# 다음과 같이 열어야 하는 경우도 있음.
from sklearn.externals import joblib
clf = joblib.load('meta.pkl')
=====================================================================================
# save to file. (1d, 2d array only)
np.savetxt("foo.txt", X1, delimiter=",")

====
a  = [['a','b'], ['cc','dd']]
np.savetxt(f, a, delimiter="\t", fmt="%s") 
=====
# append모드
a  = [['a','b'], ['cc','dd']]
with open("aa.txt", "a") as f:
    np.savetxt(f, [datetime.datetime.now().strftime("%Y%m%d-%H-%M-%S")], delimiter="\t", fmt="%s") 
    np.savetxt(f, a, delimiter="\t", fmt="%s") 
=====================================================================================
#simple 파일 
values = ['1', '2', '3']
with open("file.txt", "w") as output:
    for i in values:
        output.write(str(i)+'\n')
=====================================================================================
np.random.standard_normal(size=(2,3))
d = np.array(100 * np.random.standard_normal(size=(2,3)),dtype=np.int16)/100
=====================================================================================
a = "123456789"
print("a[:]: ", a[:])  #123456789
print("a[::]: ", a[::])  #123456789
print("a[::3]: ", a[::3]) #147
print("a[::-1]: ", a[::-1]) #987654321

================================================
# 역순으로 for loop
for t in np.arange(5)[::-1]:
    print(t)

# reversed
for t in reversed(range(5)):
    print(t)

================================================
mat = [[1, 2, 3], [4, 5, 6]]
A = list(zip(*mat))   # [(1, 4), (2, 5), (3, 6)]
B= list(np.array(A))
print(B)   # [array([1, 4]), array([2, 5]), array([3, 6])]
C = np.array(A).tolist()
print(C)  # [[1, 4], [2, 5], [3, 6]]
=========================================================

a = ["Code", "mentor", "Python", "Developer"]
print (" ".join(a))  #  Code mentor Python Developer

=====================================================================================
datetime.date(2017,7,17)+datetime.timedelta(days=4)

# 날짜 시간을 string으로
datetime.datetime.now().strftime("%Y%m%d-%H-%M-%S")  # ---> '20191112-10-44-55'

=====================================================================================
from IPython.display import display, Math, Latex
display(Math(r'F(k) = \int_{-\infty}^{\infty} f(x) e^{2\pi i k} dx'))
=====================================================================================
경과시간

import time
s=time.time()
...
e=time.time()

print(e-s,"sec")
=====================================================================================
A = np.array([[1,2,0,0,0],[2,3,5,0,0],[0,1,3,2,0],[0,0,1,2,3],[0,0,0,2,1]])
B = np.array([2,3,1,0,1]).T

X = np.linalg.solve(A,B.T)
print(X, A.dot(X))
=====================================================================================
#이진수 만들기
import numpy as np
A = np.array([range(5)],dtype=np.uint8).T
B = np.unpackbits(A,axis=1)
=====================================================================================
"""
mydata3.txt
3
5
1.2,3,4,5,6
33,1,2,3,4
2,3.4,5.5,6,6


"""
import numpy as np

file = open("mydata3.txt")
line  = file.readline()
dimX = int(line)

line  = file.readline()
dimY = int(line)

lines = file.readlines()
lines = ','.join(lines)
lines = lines.replace('\n','')
data = np.fromstring(lines,sep=',',dtype=np.float).reshape(dimX,dimY)
print(data)
=====================================================================================
#\n 없이 읽기
words = open(filename, encoding='utf-8').read().splitlines()  # list ['가게', '가격', '가구', '가구',...]

=====================================================================================
import numpy as np

A ={'a':[1,2,3],'b': [3,4,5,3,6,6,4]}  # dict

np.save('test.npy',A)

a = np.load('test.npy')  # numpy.ndarray
b = a.item()  # 저장했던 dict. 이렇게 해야, b가 a와 같은 dict가 된다.
=====================================================================================
A ={'a':[1,2,3],'b': [3,4,5,3,6,6,4]}  # dict
np.savez('test.npz',**A)  # 이렇게 저장해야, 다시 load했을 때, dict형으로 복원이 편한다.
data = np.load('test.npz')  # dict(data) --> dict형으로 쉽게 변환되고, 변환하지 않아도 dict 처럼 사용가능.
단, dict로 만들어진 A속에 dict형이 있으면 잘 복원되지 않는다. dict를 포함하고 있는 경우는 pickle로 저장하는 것이 좋다.
=====================================================================================
X = {'a': [2,3],'b': np.array([[2,3],[4,5]])}
np.save('xx.npy',X)

Y= np.load('xx.npy',allow_pickle=True)[()]

=====================================================================================
# npy는 numpy array이지만, npz는 dict형에 가깝다.
a = np.load('D:\\hccho\\data\\LJ001-0001-audio.npy')  # numpy.ndarray
b = np.load('D:\\hccho\\data\\LJ001-0001-mel.npy')  # numpy.ndarray

c = np.load('D:\\hccho\\TACOTRON\\multi-speaker-tacotron-tensorflow-master\\datasets\\son\\data\\NB10584578.0000.npz') #numpy.lib.npyio.NpzFile
print(c.keys())  # --> ['linear', 'mel', 'tokens', 'loss_coeff', 'allow_pickle']

=====================================================================================
# 파일 한줄씩 읽어, list에 저장
with open('wnids.txt', 'r') as f:
    A = [x.strip() for x in f]    # strip: 양끝의 공백, '\n'을 제거한다.
=====================================================================================
import pandas as pd

filename = 'D:\\test.txt'
data = {}
data["review"] = []
with open(filename, "r", encoding='utf-8') as file:
    data["review"].append(file.read())

    
with open(filename, "r", encoding='utf-8') as file:
    A = [x.strip() for x in file]
    
"""
Bromwell High is a cartoon comedy.
It ran at the same time as some 
other programs about school life, 
such as "Teachers".
 My 35 years in the teaching profession lead me to believe that Bromwell



==>
data
{'review': ['Bromwell High is a cartoon comedy.\nIt ran at the same time as some \nother programs about school life, \nsuch as "Teachers".\n My 35 years in the teaching profession lead me to believe that Bromwell\n\n\n']}

A
['Bromwell High is a cartoon comedy.',
 'It ran at the same time as some',
 'other programs about school life,',
 'such as "Teachers".',
 'My 35 years in the teaching profession lead me to believe that Bromwell',
 '',
 '']

=====================================================================================
# loadtxt, genfromtxt는 같은 기능이지만, 
# genfromtxt는 missing data를 다룰 수 있는 다양한 옵션이 있다.
# numpy.loadtxt: equivalent function when no data is missing.


mydata = np.genfromtxt('mydata2.txt',delimiter=',',dtype=np.float32)
mydata = np.loadtxt('mydata2.txt', delimiter=',', dtype=np.float32)    
    
=====================================================================================
import numpy as np
import pandas as pd
import datetime 

"""
2005-01-03    452500     453000     446000     451000     0.015     0.000     0.350      0.30     41750     41750     41200     41200     0.015     0.000     0.350 
2005-01-04    450000     451000     446000     447000     0.015     0.000     0.350      0.30     41450     41650     41000     41450     0.015     0.000     0.350 
2005-01-05    440000     443000     436500     443000     0.015     0.000     0.350      0.30     41200     41500     41150     41450     0.015     0.000     0.350 
2005-01-06    439000     445500     435000     435000     0.015     0.000     0.350      0.30     41650     42800     41250     42200     0.015     0.000     0.350 
2005-01-07    441000     441500     435500     440500     0.015     0.000     0.350      0.30     42200     42600     41550     41550     0.015     0.000     0.350 

"""

data = pd.read_csv("inputdata.dat", sep="\t",header = None ,index_col =None, names=['date','start1','high1','low1','close1','R1','Div1','Vol1','Rho','start2','high2','low2','close2','R2','Div2','Vol2'])

data['date'] = pd.to_datetime(data['date']).apply(pd.Timestamp.date)
data=data.set_index('date')


dd = datetime.date(2005,1,5) + datetime.timedelta(days=6)
b = data.loc[dd]['start1']
a = data.ix[0]
print(b,a)


=====================================================================================
random 선택

N = 100
A = np.arange(N)
choice = np.random.choice(N,10)  # 중복있음
choice = np.random.choice(N,10, replace=False)

B = A[choice]


===
a = np.random.rand(3) # 3개 중에 선택
a = a/np.sum(a) # 합이 1이 되로록(확률)

# method 1
i = int(np.searchsorted(np.cumsum(a),np.random.rand(1)) # 1개 선택

# method 2
j = np.random.choice(len(a),1,a.tolist())  # 1개 선택


=============================================
import numpy as np
import random
from collections import deque  #collections에는 다양한 자료형이 있다.
A = deque(maxlen=100)

A.append([3.5,1])
A.append([4.5,5])
A.append([5.5,2])
A.append([6.5,1])
A.append([7.5,3])  # deque([[3.5, 1], [4.5, 5], [5.5, 2], [6.5, 1], [7.5, 3]])

B = random.sample(A,2)  # [[4.5, 5], [5.5, 2]]
C = np.random.choice(A,2)  # ==> error. must be 1-dimensional


=============================================
Shuffle
s = np.arange(A.shape[0])
np.random.shuffle(s)

A1 = A[s]
B1 = A[s]
=====================================================================================
import numpy as np

#처음에 data 없이 빈공간만 shape에 맞게 만들기
a = np.empty(0).reshape(0,3,2)
b= np.array([[[1.2,2],[3,4],[5,6]]])
c = np.concatenate((a,b),0)
=====================================================================================
import argparse

parser = argparse.ArgumentParser(description='Easy Implementation of DCGAN')

#다음과 같이 하면, -h(help)에서 default argument 값도 보여준다.
parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)



# parameters
parser.add_argument('datasets', metavar='N', type=str, nargs='+', choices=['celebA', 'lsun', 'mnist'],
           help='name of dataset to download [celebA, lsun, mnist]')
# 위의 경우와 같이 -- 없이 'datasets'만 있는 경우, argument값만 넘겨야 한다.
# nargs='+' ==> 여러개의 argument가 list로 들어간다.


parser.add_argument('--filelist', type=str, default='filelist.txt')
parser.add_argument('--out_dir', type=str, default='./output', help="where to put output files")
parser.add_argument('--epochs', type=int, default=10)
parser.add_argument('--batch_size', type=int, default=32)
parser.add_argument('--batch_size2', required=True, choices=["aa","bb"])   <----- required=True 항목이 빠지면, usage를 출력하면서 끝난다.

# 옵션에 따라 하나의 parameter 설정   ====> 'flip'에 True 또는 False를 주고 싶을 때....
parser.add_argument("--flip", dest="flip", action="store_true", help="flip images horizontally")  
#  ---> action="store_true"  ==> default로 False. 반면 action="store_false"  ==> True
parser.add_argument("--no_flip", dest="flip", action="store_false", help="don't flip images horizontally")
parser.set_defaults(flip=True)
===
# train_flag에 True 또는 False를 주고 싶을 때....
parser.add_argument('--train', dest='train_flag', action='store_true')
parser.add_argument('--test', dest='train_flag', action='store_false')
parser.set_defaults(train_flag=False)
> python xxx.py --train    ====> train_flag에 True값
> python xxx.py --test     ====> train_flag에 False값

===
args = parser.parse_args()
filelist_dir = args.filelist
output_dir = args.out_dir

total_epoch = args.epochs
batch_size = args.batch_size

print(filelist_dir, output_dir, total_epoch,batch_size  )

> python  zzz.py -h   ==> help 출력
=====================================================================================
# lbfgs를 default로 true로하고, --adam 을 argument로 넣으면, lbfgs가 false
parser.add_argument("--adam",dest='lbfgs',help="True=lbfgs, False=Adam", action="store_false")
parser.set_defaults(lbfgs=True)
=====================================================================================
import argparse
parser=argparse.ArgumentParser()
parser.add_argument('-auto', action='store_false', )
parser.add_argument("--max_epochs", type=int, default=100, help="number of training epochs")
args=parser.parse_args()
print(args)
print(vars(args))  # 내장함수 vars를 이용하여 dict형으로 변환
==========================================================
아래 2가지 모두 가능.
>python xxx.py --batch_size=32
>python xxx.py --batch_size 32

=====================================================================================
parser = argparse.ArgumentParser()
parser.add_argument('--batch_size', default=100, type=int, help='batch size')
parser.add_argument('--train_steps', default=1000, type=int,help='number of training steps')


#args = parser.parse_args()

args = parser.parse_args(sys.argv[1:])  # 새로운 argument추가는 불가. 이미 정의된 argument update가능

=====================================================================================
parser = argparse.ArgumentParser()
args = parser.parse_args()

args.num_hidden = 10
args.num_epoch = 20
print(args)


=====================================================================================
flags = tf.app.flags
이 함수는 argparse 모듈과 같은 역할을 합니다. argparse보다 나은 점은 저가 볼 때는 굳이 argparser를 import 할 필요 없이 아래와 같이 추가만 하면 됩니다.

flags = tf.app.flags
flags.DEFINE_integer("epoch", 25, "Epoch to train [25]")
flags.DEFINE_string("sample_dir", "samples", "Directory name to save the image samples [samples]")
flags.DEFINE_boolean("is_crop", False, "True for training, False for testing [False]")
FLAGS = flags.FLAGS

if not os.path.exists(FLAGS.checkpoint_dir):
    os.makedirs(FLAGS.checkpoint_dir)

flags에 tf.app.flags 를 통해 객체를 저장하고 DEFINE_integer나 DEFINE_string 을 통해 아래 argparse와 같은 역할을 할 수 있습니다

=====================================================================================
Examples = collections.namedtuple("Examples", "paths, inputs, targets, count, steps_per_epoch")
=====================================================================================
image 읽기

img = skimage.io.imread(path)  ==> 정수 data
resized_img = skimage.transform.resize(crop_img, (img_size, img_size))  #정수 data image가 넘어와도 float로. preserve_range=True(정수형태지만, type은 float), order로 변환방법 설정. 0: Nearest-neighbor 1: Bi-linear (default) 2: Bi-quadratic 3: Bi-cubic 4: Bi-quartic 5: Bi-quintic

skimage.io.imshow(img)
plt.show()
======
im = scipy.misc.imread   ==> 정수 data
im = scipy.misc.imresize(im, self.resize)  #정수값이 return.  ----> deprecated in Scipy 1.14.3 ---> skimage.transform.resize를 사용해야 된다.

scipy.misc.imsave(save_path, im)
=====================================================================================
from scipy.misc import imread, imresize   ---> imread, imresize가 deprecated되었다.

scipy.misc.imread   ---> 정수 uint8   ---> from imageio import imread 사용하면 된다.

scipy.misc.resize   ---> 정수 uint8 ---> from PIL import Image릉 이용해서, array를 Image로 만든 후, resize하고 np.array로 comverting한다.  ---> uint8

from PIL import Image
np.array(Image.fromarray(img).resize((10,10)))  # 여기서 img: uint8 numpy array


=====================================================================================
import os, glob
a = os.path.join("../tensorflow-style-transfer-master","images", "*.jpg") #string을  \로 이어  path를 만든다.
b = glob.glob(a) # wild card를 풀어  filename list를 만든다.
=====================================================================================
input_dir = "D:\\hccho\\CycleGAN-TensorFlow-master\\data\\apple2orange\\testA"
x = os.scandir(input_dir)

for i in x:
    print(i.path)
=====================================================================================
import gzip,os
import numpy as np
import skimage.io
import scipy.misc
import matplotlib.pyplot as plt

data_dir = 'D:\hccho\ML\PythonCode\CommonDataset\mnist'
fd = os.path.join(data_dir,'train-images-idx3-ubyte.gz')
with gzip.open(fd, 'rb') as f:
    loaded = np.frombuffer(f.read(), np.uint8, offset=16)
    trX = loaded.reshape((60000,28,28,1)).astype(np.float)  


skimage.io.imshow(np.squeeze(trX[0]/255.0))
plt.show()
skimage.io.imshow(np.squeeze((trX[0]/255.0 +1)/2))
plt.show()


plt.imshow(np.squeeze(trX[0]/255.0))
plt.show()
plt.imshow(np.squeeze((trX[0]/255.0 +1)/2))


#scipy.misc.imsave("a.jpg",np.squeeze(trX[0]/255.0))  # 0~1
#scipy.misc.imsave("b.jpg",np.squeeze((trX[0]/255.0 +1)/2)) 0.5~1

img1 = skimage.io.imread("a.jpg")
img2 = skimage.io.imread("b.jpg")
=====================================================================================
from PIL import Image
import os, glob

#image_files = glob.glob("./*.png")
image_files = glob.glob("*.png")

print(image_files)
images = [Image.open(f) for f in image_files]
images = images*10  # 반복
gif = images[0]
gif.save(fp="result.gif", format='gif', save_all=True, append_images=images[1:],duration=800)  # duration 지정
print(Image.open("result.gif").n_frames)


###  동영상 gif로 변환
from moviepy.editor import *
from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip
VideoFileClip('D:/hccho/RL/ReinforcementZeroToAll-master/movie/openaigym.video.0.11248.video000000.mp4').speedx(4).write_gif('out.gif')

# VideoFileClip(filename).write_videofile("xxx.mp4")  # save as
#ffmpeg_extract_subclip(filename, 0, 60*2+20, targetname="xxx.mp4")  # 초 단위 추출-- 부분 추출

=====================================================================================
import skimage.io
from tensorflow.examples.tutorials.mnist import input_data   # ---> TF 2.x에서는 없음.
mnist = input_data.read_data_sets('D:\hccho\CommonDataset\mnist', one_hot=True)
inputs = mnist.train.images
labels = mnist.train.labels
n  = 14
skimage.io.imshow(inputs[n].reshape(28,28))
print(labels[n])
=====================================================================================
# sklean에서 제공하는 MNIST(자체 포맷) ---> sklearn으로 다운받으면 30초, 이미 다운 받은 cache로 하면, 17~20초
import time
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_openml

s_time = time.time()

mnist = fetch_openml('mnist_784',version=1,data_home=r'D:\hccho\CommonDataset\mnist\scikit_learn_data')  # 14M. data_home=None ---> C:\Users\BRAIN\scikit_learn_data 아래에...

print(mnist.keys())

print(mnist['data'].shape, mnist['target'].shape)   # 'data', 'target'모두 정수 numpy array
print(mnist['data'][0], mnist['target'][0])


plt.imshow(mnist['data'][0].reshape(28,28),cmap='binary')  # cmap = 'binary'(흑백으로 보인다)
plt.show()

print(time.time()-s_time)

=====================================================================================
# image file 읽어와 보여주기
x = ['a.jpg','b.jpg','c.jpg','d.jpg']

img = imread(x[1])
plt.subplot(2,1,1)
plt.imshow(img)


img = imread(x[2])
plt.subplot(2,1,2)
plt.imshow(img)

plt.show()
=====================================================================================
import matplotlib.pyplot as plt
from PIL import Image

img = Image.open('/home/hccho2/datasets/mj_evaluation/000000-완고스레.jpg')
plt.imshow(img)
plt.show()
=====================================================================================
def change_image_format():
    import os, glob
    a = os.path.join("D:\hccho\StackGAN-hccho\StcakGAN-Result", "*.png") #string을  \로 이어  path를 만든다.
    b = glob.glob(a) # wild card를 풀어  filename list를 만든다.
    
    
    for f in b:
        image = Image.open(f)
        image.save(f[:f.find('png')] + 'jpg')

=====================================================================================
# numpy image concat
# a: shape =(5, 256, 256, 3)

np.concatenate(a,axis=0)   ==>    (1280, 256, 3)  <---- a[0],a[1],a[2],a[3],a[4] 가 axis = 0으로 concat된다.
np.concatenate(a,axis=1)   ==>    (256, 1280, 3)
np.concatenate(a,axis=1)   ==>    (256, 256, 15)
=====================================================================================
img_path = "cat.jpeg"

im = plt.imread(img_path)
h,w,c = im.shape
h1 = w1 = 512
img_raw = tf.io.read_file(img_path)
img_tensor = tf.reshape(tf.image.decode_image(img_raw),im.shape)

img_upsampled = tf.image.resize_images(img_tensor,size=(h1,w1),method=1)   #BILINEAR = 0, NEAREST_NEIGHBOR = 1, BICUBIC = 2, AREA = 3



sess = tf.Session()
x = sess.run(img_tensor)
x_upsampled = sess.run(img_upsampled)

fig = plt.figure()
fig.suptitle("Upsampling", fontsize=16)
ax = plt.subplot("121")
ax.set_title("Origin")

ax.imshow(x,extent=[0,w,0,h])
ax.set_aspect('equal',anchor ='SW')



ax = plt.subplot("122")
ax.set_title("Resize")

ax.imshow(x_upsampled,extent=[0,h1,0,w1])
ax.set_aspect('equal',anchor ='SW')


plt.axes
plt.show()



=====================================================================================
print(os.listdir("../"))     <---모든 디렉토리

=====================================================================================
#list 원소 모두 곱하기
from functools import reduce

A = [2,3,5]
result = reduce(lambda x, y: x * y, A)
print(result)

#np.prod로 하면 더 간단함.
np.prod(A)
=====================================================================================
#array 초기화 
empty,empty_like, ones, ones_like, zeros, zeros_like, full, full_like
x = np.arange(6)
x = x.reshape((2, 3))
x = np.zeros_like(x)



# array random 초기화: rand, randn, ranint, random
A = np.random.rand(2,3,4)  # 같은 기능  np.random.random((2,3,4))
A = np.random.randn(2,3,4) # 표준정규분포, 비표준정규분포는 sigma * np.random.randn(...) + mu
A = np.random.randint(10, size=(9, 6))


random sample n개 뽑기
B = np.random.normal(1,2,10)
=====================================================================================
A.shape + (1,)
(1,) + A.shape
=====================================================================================
from functools import partial

=====================================================================================
class HC:
    def __init__(self,a):
        self._a = a
    @property
    def x(self):
        return self._a
    @x.setter 
    def x(self,xx):
        self._a = xx
        
A = HC(4)
A.x = 3
print(A.x)
=====================================================================================
class Info(object):
    pass        
info = Info()

# class의 property이름을 임의로 만들 수 있다.
info.a = -1
info.b = 'xx'

=====================================================================================
getattr
=====================================================================================
print("float: {:0.8f}, int: {:10d}".format(2.34, 45))  # float: 2.34000000, int:         45
print("{:10}".format('test')) # left align             test      
print("{:>10}{:>10}".format('test',123)) # right align #      test       123
print("{:>10}{:06d}".format('test',123)) # fill 0, 6digit #       test000123
print("{:06.2f}".format(3.14156))   #003.14
print("{:06}".format(35))  # 000035
print("{:,.2f}".format(1233456.8934))  # 1,233,456.89
print("{:.2f}".format(3.25148))  # 3.25
print("{:.2%}".format(0.325148))  # 32.51%
print('{:.2g}'.format(1234.2512521)) # 1.2e+03 ------> %f(부동소수형 실수)와 %e (소문자 'e' 지수 표기) 의 단축형 표기
=====================================================================================
import collections

#with codecs.open(input_file, "r", encoding=self.encoding) as f:
#    data = f.read() # data: <class 'str'>


data = 'abcd aaa bb d fff'
counter = collections.Counter(data) # Counter({' ': 4, 'a': 4, 'b': 3, 'c': 1, 'd': 2, 'f': 3})

x = sorted(counter.items()) # [(' ', 4), ('a', 4), ('b', 3), ('c', 1), ('d', 2), ('f', 3)]
y = sorted(counter.items(),key=lambda x: -x[1]) #[('a', 4), (' ', 4), ('b', 3), ('f', 3), ('d', 2), ('c', 1)]
z = sorted(counter.items(),key=lambda x: x[1])  #[('c', 1), ('d', 2), ('b', 3), ('f', 3), ('a', 4), (' ', 4)]


chars, _ = zip(*y) # alphabet 만 
vocab = { ch:i for i,ch in enumerate(chars) } # alphabet에 숫자에 대응 부여
tensor = np.array(list(map(vocab.get, data))) # data를 숫자로 변환
=====================================================================================
# natural sorting
from natsort import natsorted
a = ['./saved_model\\model-1000.pth', './saved_model\\model-2000.pth', './saved_model\\model-500.pth']

natsorted(a) # ['./saved_model\\model-500.pth', './saved_model\\model-1000.pth', './saved_model\\model-2000.pth']


=========================================
# dict 정렬
vocab = {'a': 3,'b':7, 'c': 1}
X =sorted(vocab, key=vocab.get, reverse=True)  #내림차순 list
Y =sorted(vocab, key=vocab.get, reverse=False) #오름차순 list
=====================================================================================

def change_one_hot_label(X,n_dim=10):
    X = X.astype(np.int32)
    T = np.zeros((X.size, n_dim))
    for idx, row in enumerate(T):
        row[X[idx]] = 1

    return T 

print(change_ont_hot_label(np.array([2,3,2]),5))
[[ 0.  0.  1.  0.  0.]
 [ 0.  0.  0.  1.  0.]
 [ 0.  0.  1.  0.  0.]]
=====================================================================================
one-hot
y =[2,3,4]
x = np.zeros((3,10))
x[np.arange(3),y]=1

=====================================================================================
ind =[2,1,8]
y=[-1,-2,-3]
x = np.zeros((3,10))
x[np.arange(3),ind]=y
==> 
array([[ 0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],
       [ 0., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -3.,  0.]])
=====================================================================================
# 특정값을 가지는 array의 index 추출(찾기)
A = np.array([2,3,2,2,1,5])
B = np.array([1,3,4,2,2,5])
ind_A = np.flatnonzero(A == 2)
ind_B = np.flatnonzero(A == B)
=====================================================================================
def multiply(*args):
    z = 1
    for num in args:
        z *= num
    print(z)

multiply(4, 5)
multiply(10, 9)
multiply(2, 3, 4)
multiply(3, 5, 10, 6)

def print_kwargs(**kwargs):  # dict형으로 처리
        print(kwargs)

print_kwargs(kwargs_1="Shark", kwargs_2=4.5, kwargs_3=True)

=======

def safe_division_d(number, divisor, **kwargs):
	ignore_overflow = kwargs.pop(‘ignore_overflow’, False)
	ignore_zero_div = kwargs.pop(‘ignore_zero_division’, False)
	if kwargs:
		raise TypeError(‘Unexpected **kwargs: %r’ % kwargs)


pop 메서드로 kwargs 딕셔너리에서 원하는 키워드 인수를 꺼낸다. 키가 없을 때의 기본값은 pop 메서드의 두번째 인수로 지정한다. 
마지막으로 kwargs에 더는 남아 있는 키워드가 없음을 확인하여 호출하는 쪽에서 올바르지 않은 인수를 넘기지 않게 한다.
=====
def my_func(x,*args, **kwargs):   # arguments, keyward argument
    # args: tuple로 인식
    # kwargs: dict로 인식  ===> named arguemnt가 여기로 들어온다.
    print(x)
    for w in args:
        print('args: ', w)
        
    d  = kwargs.pop('name', '')  # 없을 경우에 두번째 argument를 default값으로
    print(d)
    d  = kwargs.pop('age', 0)   # 없을 경우에 두번째 argument를 default값으로
    print(d)

my_func(33, 1,2,3,name='cho')  # 1,2,3  ---> args,   named argument는 kwargs


=====
=====================================================================================
# grid
#xx, yy = np.meshgrid(np.arange(-1,1, 1), np.arange(-2, 2, 1))
xx, yy = np.meshgrid(np.linspace(4,-4,10),np.linspace(4,-4,10))

z = np.c_[xx.T.ravel(), yy.T.ravel()]

array([[-1, -2],[ 0, -2],[-1, -1],[ 0, -1],[-1,  0],[ 0,  0],[-1,  1],[ 0,  1]])
=====================================================================================
grid = np.mgrid[0:2, 0:3].reshape(2,-1).T
=====================================================================================

import os
filename='E:\\dir1\\dir2\\aa.txt'
os.path.sep ===> '\\'  or '/'   ----> os.sep도 있는데, 이것보다는 os.path.sep르 사용해야.... https://stackoverflow.com/questions/6900520/which-one-should-i-use-os-sep-or-os-path-sep
os.path.dirname(filename)  # 'E:\\dir1\\dir2'
os.path.abspath(filename)  # 'E:\\dir1\\dir2\\aa.txt'
os.path.basename(filename)  # 'aa.txt'
os.path.splitext(filename)  ==> ('E:\\dir1\\dir2\\aa','txt')  이걸 이용해서 확장자 변경가능
os.path.splitext(os.path.basename(filename))[0]  # ('aa', '.txt')
os.path.join(os.path.dirname(filename), 'aaaa.dat')  # 'E:\\dir1\\dir2\\aaaa.dat'


# all sub directory
dir = 'D:\hccho\speech-recognition\speech_commands\speech_dataset'
all_subdir = [x[0] for x in os.walk(dir) if x[0] != dir]


=====================================================================================
# simple graph
import numpy as np
import matplotlib.pyplot as plt
def f(x,a):
    return (0.5*(1+a))* x + (0.5 * (1 - a)) * np.abs(x)

x = np.linspace(-3,3,100)
y= f(x,0.2)

plt.figure(figsize=(6, 6))
plt.plot(x, y, c=[1, 0.2, 0.05], linewidth=8)  # c=[1, 0.2, 0.05] <--RGB color
plt.xlim([-3, 3])
plt.ylim([-3, 3])
plt.show()
=====================================================================================
# simple scatter
def g(p):
    r = np.sqrt(p) * 3.0
    rad = np.pi * 4.0 * np.sqrt(p)
    x = r * np.cos(rad)
    y = r * np.sin(rad)
    return x,y


p = np.linspace(0,1,100)
x,y = g(p)

plt.figure(figsize=(6, 6))
plt.scatter(x, y, c=[0.8, 0.5, 0.5],s=10)
plt.xlim([-3, 3])
plt.ylim([-3, 3])
plt.show()
=====================================================================================
X = {'a': 12,'b':'xx'}

print('axx {b}zz{a}'.format(**X))
=====================================================================================
# progress bar tqdm
from tqdm import tqdm,trange
from time import sleep
# ncols = bar의 폭 조절
with tqdm(total=200,ncols=70) as pbar:
    for i in range(10):
        sleep(0.1)
        if (i+1) % 2 == 0:
            tqdm.write("Done task %i" % (i+1))   # print와 동일  ----> 줄바꿈 생김.
        pbar.set_description("Processing {}-{}".format(i,i*10))  # progress bar 앞부분에 출력
        pbar.update(20)  # 위에서 설정한 total = 200을 20씩 업데이트 한다. 그러면 10번 실행. loop 회수와 일치시키면 됨
=====================================================================================
# Multi Processing,    if __name__ == '__main__': <--- 이것이 있는 파일에서 실행해야 함.
# Python에서는 thread로 처리 속도가 향상되지 않는다.
# multiprocessing으로 하면 처리 속도가 향상된다.
=====================================================================================
import time
from tqdm import tqdm
from contextlib import closing
from multiprocessing import Pool, Process
from concurrent.futures import ProcessPoolExecutor
from functools import partial
import threading
from collections import deque
import numpy as np
def isPrime2(n):
    if n==2 or n==3: return True
    if n%2==0 or n<2: return False
    for i in range(3,int(n**0.5)+1,2):   # only odd numbers
        if n%i==0:
            return False    

    return True
items = [23245457771477,23245457771477,23245457771477,23245457771477,12345,456789,23245457771477,23245457771477,23245457771477,23245457771477,23245457771477]
items = items + items + items + items + items + items + items + items + items
def test1():
    # https://medium.com/@lih.verma/multi-processing-in-python-process-vs-pool-5caf0f67eb2b
    # data based parallelism( 하나의 함수-다양한 argument)
    results = []
    fn = partial(isPrime2)
    with closing(Pool(processes=None)) as pool:
        for out in tqdm(pool.imap_unordered(isPrime2, items), total=len(items), desc="Prime Check"):
            results.append(out)
    print(results)
    
def test1_1():
    # rfunction based parallelism(여러가지 함수 실행도 가능)   ----> 속도 향상됨
    # https://stackoverflow.com/questions/10415028/how-can-i-recover-the-return-value-of-a-function-passed-to-multiprocessing-proce
    jobs = []
    for item in items:
        job = Process(target=isPrime2, args=(item,))
        jobs.append(job)
        job.start()
        
    for job in tqdm(jobs):
        job.join()    
    
    
def test2():
    # 단순히 serial하게 처리. cpu process 1개만 사용.
    for item in tqdm(items, total=len(items), desc="Prime Check"):
        isPrime2(item)

def test3():
    # CPU 집약적인 작업을 위해 ProcessPoolExecutor를 사용하는게 좋습니다. ThreadPoolExecutor는 네트워크 작업 또는 I / O에 더 적합합니다
    executor = ProcessPoolExecutor(max_workers=None)
    futures = []

    for item in items:
        fn = partial(isPrime2,item)
        futures.append(executor.submit(fn))
        
    n_frames = [future.result() for future in tqdm(futures)]
    n_frames = [n_frame for n_frame in n_frames if n_frame is not None]
    print(n_frames)


        
        
# 다음의 test4, test5는 threading.Thread를 상속받아서 처리하거나 직접 이용하는 차이가 있다.
def test4():
    # threading.Trhead는 병렬처리를 하는 것은 아니다.
    # https://www.quantstart.com/articles/parallelising-python-with-threading-and-multiprocessing/
    import queue
    que = queue.Queue()
    threads = []
    for i in range(len(items)):
        #thread = threading.Thread(target=isPrime2,args=(items[i],))
        thread = threading.Thread(target = lambda q,arg1: q.put(isPrime2(arg1)),args=(que,items[i],))
        thread.start()
        threads.append(thread)
    # 종료할 때까지 대기
    for thread in threads:
        thread.join()

    result = []
    for i in range(len(items)):  # q.qsize()
        result.append(que.get())
    print(result)

def test4_1():   # tensorflow의 coord = tf.train.Coordinator()를 이용하여 안정적으로 종료시키기. request_stop(), coord.should_stop()
	N = 100000
	num_thread = 4

	# parallel이  소극적으로 이루어지는 것 같다~~

	class Agent(threading.Thread):
		def __init__(self,id,coord):
			super(Agent,self).__init__()
			self.id = id
			self.coord = coord
		def run(self):
			global n
			while not self.coord.should_stop():
				print('id: ', self.id, '====== ', n)
				n=n+1

				if n > N:
					self.coord.request_stop()


	coord = tf.train.Coordinator()

	agents = [Agent(i,coord) for i in range(num_thread)]

	for agent in agents:
		agent.start()


	waiting = True  # waiting == True이면 join의 효과를 thread들이 끝날때 까지 기다린다. False이면, 그 다음 라인을 실행한다.
	if waiting == True:

		method = 1
		if method ==1:
			for agent in agents:
				agent.join()
		elif method==2:
			coord.join(agents)  # Wait for threads to terminate.
		else:
			coord.wait_for_stop()    # Wait till the Coordinator is told to stop.      이건 완전히 기다리지 못하네....
			

	print('Done')




n=0
def test5():
	# parallel이  소극적으로 이루어지는 것 같다~~
    import queue
    num_thread = 4
    N = len(items)
    n=0
    que = deque(maxlen=N)
    class Agent(threading.Thread):
        def __init__(self,id):
            super(Agent,self).__init__()
            self.id = id
        def run(self):
            global n
            while n<N:
                #que.append([self.id,n,isPrime2(np.random.randint(100000,1000000))])
                que.append([self.id,n,isPrime2(items[n])])
                n=n+1
    
    agents = [Agent(i) for i in range(num_thread)]
    
    for agent in agents:
        agent.start()
        
    for agent in agents:
        agent.join()
    
    print(que)
if __name__ == '__main__':
    s = time.time()
    print('test1-multiprocess-Pool')
    test1()
    print(time.time()-s," sec")
    print('='*20)

    print('test1_1-multiprocessing-Process')
    s = time.time()
    test1_1()
    print(time.time()-s," sec")
    print('='*20)

    print('serial 처리')
    s = time.time()
    test2()
    print(time.time()-s," sec")
    print('='*20)
    
    print('test3-ProcessPoolExecutor')
    s = time.time()
    test3()
    print(time.time()-s," sec")
    print('='*20)

    print('test4-thread')
    s = time.time()
    test4()
    print(time.time()-s," sec")
    print('='*20)

    print('test5-thread')
    s = time.time()
    test5()
    print(time.time()-s," sec")
    print('='*20)

=====================================================================================
from multiprocessing import Process, Queue
 
sentinel = -1
 
def creator(data, q):
    #Creates data to be consumed and waits for the consumer
    #to finish processing
    
    print('Creating data and putting it on the queue')
    for item in data:
        q.put(item)
 

def my_consumer(q):
    #Consumes some data and works on it
    #In this case, all it does is double the input
   
    while True:
        data = q.get()
        print('data found to be processed: {}'.format(data))
        processed = data * 2
        print(processed)
 
        if data is sentinel:
            break


if __name__ == '__main__':
    q = Queue()
    data = [5, 10, 13, -1]
    process_one = Process(target=creator, args=(data, q))
    process_two = Process(target=my_consumer, args=(q,))
    process_one.start()
    process_two.start()
 
    q.close()
    q.join_thread()
 
    process_one.join()
    process_two.join()

=====================================================================================




numpy.testing.assert_allclose
numpy.array_equal
=====================================================================================
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

# tensorflow warning 
import logging
logging.getLogger('tensorflow').disabled = True
=====================================================================================
def sigmoid(x):
    "Numerically-stable sigmoid function."
    if x >= 0:
        z = exp(-x)
        return 1 / (1 + z)
    else:
        z = exp(x)
        return z / (1 + z)
	
def sigmoid(x):
    pos_mask = (x >= 0)
    neg_mask = (x < 0)
    z = np.zeros_like(x,dtype=float)
    z[pos_mask] = np.exp(-x[pos_mask])
    z[neg_mask] = np.exp(x[neg_mask])
    top = np.ones_like(x,dtype=float)
    top[neg_mask] = z[neg_mask]
    return top / (1 + z)
	
=====================================================================================
########## example 1
# index 3,5,1이 주어져 있으면, index [2,3,4], [4,5,6], [0,1,2] 의 값이 1인 array 만들기   

i0 =np.array([3,5,1])

b = np.vstack([i0-1,i0,i0+1]).T   # or b = np.array(list(zip(i0-1,i0,i0+1)))
c = np.tile(np.arange(3),[3,1]).T

a = np.zeros((3,10))
a[c,b]=1



######### example 2
batch_size=3
#alignment0 = np.random.randn(batch_size,10)
alignment0 = np.array([[ 0.53147691,  4.71839748, -1.29035515, -0.98584769, -0.27640441,
         1.90273668, -1.45894385, -0.8311972 ,  0.14568322, -1.10923294],
       [-0.60512821, -0.41684329, -0.34283085, -0.7411493 ,  0.29670264,
         0.29437037, -1.65130632, -0.21103169, -0.79904658,  0.25820306],
       [-1.0253159 ,  0.39568011,  0.42450628, -0.16309257,  0.4185017 ,
        2.89342868,  3.35246116, -0.19832729, -1.55400021,  0.54946349]])


prev= np.array([7,0,2])

Y = np.zeros((batch_size,10))
Y[np.tile(np.arange(batch_size),[batch_size,1]).T, np.vstack([prev-1,prev,prev+1]).T ] = 1
alignment_new = alignment0*Y

=====================================================================================
# with
class controlled_execution:
    def __enter__(self):
        print("enter...")
        return np.arange(4).reshape(2,-1)
    def __exit__(self, type, value, traceback):
        print("exit...")
        


with controlled_execution() as xx:
    print(xx.shape)
=====================================================================================
def softmax(x):  
    x = x - np.max(x,axis=-1,keepdims=True) 
    return np.exp(x) / np.sum(np.exp(x),axis=-1,keepdims=True)
=====================================================================================

# list, numpy 모두 그냥 할당하면 같은 곳 참조, copy를 해야

a = np.array([2,3,4])
b=a  # b=a.copy()
b[0] = 10

print(a,b)  #[10  3  4] [10  3  4]


a = [2,3,4]
b=a   # b=a.copy()
b[0] = 10

print(a,b)  #[10  3  4] [10  3  4]

=====================================================================================
#deep copy
def f(params):
    X = params[:] # 얕은 복사
    X[0] += 1.0   # params의 값도 같이 바뀐다.
    X.pop(2)
    return X

def copy_test():
    a = np.array([[1,2],[3,4]]).astype(np.float16)
    b = np.zeros_like(a)
    c = np.zeros_like(a)
    
    b = a   # shallow copy
    
    deep_copy=False
    if deep_copy:
        c[...] = a  # deep copy(c가 미리 선언되어 있어야 한다.  c = np.zeros_like(a)  )  <=========== 기억해 둘 것.
    else: c = a[:]   # c =a 와 동일
    b[1] = [3.6,5.6]  # a 값이 바뀐다. c는 별개 
    c[1] = [3.9,5.9]  # a,b와는 별개
    
    print("a: ", a,'\nb: ',b,'\nc: ',c)


def copy_test2():
    a = np.array([1.1,2,3])
    b = np.array([10.0,20,30])
    c = np.array([100.0,200,300])
    A=[a,b,c]
    
    B = f(A)
    B[0] = np.array([1.1,2,3])*2.0  #A의 값도 같이 바뀐다.
    print('A:', A)
    print('B:', B)

copy_test()
print('='*10)
copy_test2()
=====================================================================================
a = np.zeros(3)

a[1] = 5

b = np.zeros(3)
c = np.zeros(3)
d = np.zeros(3)
e = np.zeros(4)


b[:]=a  # value만 복사    <----------------------------기억해 둘 것.
c = a.copy()


d = a[:]  # referenc 복사
e = a # refernce 복사

a[0] = 7
a[1] = -7

print(a)  # array([ 7., -7.,  0.]
print(b)  # array([0., 5., 0.])
print(c)  # array([0., 5., 0.])
print(d)  # array([ 7., -7.,  0.]
print(e)  # array([ 7., -7.,  0.]


=====================================================================================
import itertools
# merge, list 병합
x = [['Bromwell', 'High', 'is', 'a'],['comedy.', 'It']]
y = list(itertools.chain(*x))
=====================================================================================
import itertools
import nltk
x = ["This is a foobar-like sentence.","Good muffins cost $3.88\nin New York.  Please buy me\ntwo of them.\nThanks."]
y= [nltk.word_tokenize(sent) for sent in x]
w = list(itertools.chain(*y))
z = nltk.FreqDist(w)    # zz=collections.Counter(w) 같은 결과
vocab = z.most_common(5) # zz.most_common(5)

=====================================================================================
import re

_WORD_SPLIT = re.compile(b"([.,!?\"':;)(])")
def basic_tokenizer(sentence):
    """Very basic tokenizer: split the sentence into a list of tokens."""
    words = []
    for space_separated_fragment in sentence.strip().split():
        if isinstance(space_separated_fragment, str):
            word = str.encode(space_separated_fragment)
        else:
            word = space_separated_fragment  
        words.extend(re.split(_WORD_SPLIT, word))
    return [w.decode('utf-8') for w in words if w]
 
s = 'Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.'
x = basic_tokenizer(s) # ['Can', 'we', 'make', 'this', 'quick', '?', 'Roxanne', 'Korrine', 'and', 'Andrew', 'Barrett', 'are', 'having', 'an', 'incredibly', 'horrendous', 'public', 'break-', 'up', 'on', 'the', 'quad', '.', 'Again', '.']

y=[w.strip() for w in s.split(' ') if w] #['Can', 'we', 'make', 'this', 'quick?', 'Roxanne', 'Korrine', 'and', 'Andrew', 'Barrett','are', 'having', 'an', 'incredibly', 'horrendous', 'public', 'break-', 'up', 'on', 'the', 'quad.', 'Again.']

=====================================================================================
'hello world'.split() --> 공백으로 split
list('hello world')  --> 한 글자씩 split

=====================================================================================
import re
from konlpy.tag import Okt
a1 = re.sub("[^가-힣ㄱ-ㅎㅏ-ㅣ\\s]", "", '아 01123 더빙.. 진짜 짜증나네요 목소리')  # --> '아  더빙 진짜 짜증나네요 목소리'
a2 = re.sub("[^가-힣ㄱ-ㅎㅏ-ㅣ0-9\\s]", "", '아 01023 더빙.. 진짜 짜증나네요 목소리') # --> '아 01023 더빙 진짜 짜증나네요 목소리'
a4 = re.sub("[^A-Za-z\\s]","",'copyright 2000 dou &glas: n. honorof, jill mccullough & barbara somerville.') # alphabet만 남기기
a5 = re.sub("[^A-Za-z0-9\\s]","",'copyright 2000 dou &glas: n. honorof, jill mccullough & barbara somerville.')# alphabet, 숫자만 
print(a1)
print(a2)
=============
s = '9976970\t아 더빙.. 진짜 짜증나네요 목소리\t0\n'

print(list(s)) # 한자씩 분리 --> ['9','9','7','6','9','7','0','\t','아','','더','빙','.','.','','진','짜','','짜','증','나','네','요','','목','소','리','\t','0','\n']
print(s.split())   # 공백으로 분리 ---> ['9976970', '아', '더빙..', '진짜', '짜증나네요', '목소리', '0']
print(re.split(r'\t+', s.strip())) # tap으로 분리. --->  ['9976970', '아 더빙.. 진짜 짜증나네요 목소리', '0']
print(s.strip().split('\t'))  # tap으로 분리. ---> ['9976970', '아 더빙.. 진짜 짜증나네요 목소리', '0']

okt=Okt()
print(okt.morphs('아 더빙.. 진짜 짜증나네요 목소리', stem=True)) # ['아', '더빙', '..', '진짜', '짜증나다', '목소리']
print(okt.morphs('아 더빙.. 진짜 짜증나네요 목소리', stem=False)) # ['아', '더빙', '..', '진짜', '짜증나네요', '목소리']
=====================================================================================
# 지정한 character 앞에 공백 삽입
# method1
marks = re.compile('([?!\(\)\[\]])')
s= '[안녕? 너는 왜!'
ss = re.sub(marks, r' \1',s)  # ' [안녕 ? 너는 왜 !'

# method2
x = '?![]()'
marks2 = re.compile(f'([{re.escape(x)}])')
ss2 = re.sub(marks2, r' \1',s)
=====================================================================================
#  numpy array --> pandas DataFrame
data = np.array([[2,3,4.5],[3,4,2]])
df = pd.DataFrame(data,columns=['A','AA','B'])  
print(df)

# numpy array를 DataFrame에 칼럼으로 추가
df=df.join(pd.DataFrame(data,columns=['C','CC','D']))
print(df)

# column 삭제
df.drop('CC', axis=1, inplace=True)
print(df)
=====================================================================================
window, ubuntu 모두에서 사용가능한 file path 표기법

- 현재 디렉토리를 뜻하는 . 표기할 것
- 역 슬래쉬 안되고, 슬래쉬(1개 또는 2개)
=====================================================================================
a = np.arange(10)
idx = a>5  # array([False, False, False, False, False, False,  True,  True,  True,True])
print(a[idx])  # [6 7 8 9]
print(np.where(a>5))  # (array([6, 7, 8, 9], dtype=int64),)

=====================================================================================
# 살아 있는 놈만 뽑기
gt = gt[np.nonzero(np.any(gt > 0, axis=1))]
=====================================================================================
1. 파일 이름으로 부터 로드:
a = importlib.import_module('cc.any')  <----cc\any.py
a.ff(2,3)


2. 함수이름(string)으로 부터 로드:
globals()['ff'](2,3)
=====================================================================================
# numpy array exchange columns
boxes_.T[[0,1,2,3]] =  boxes_.T[[1,0,3,2]]
=====================================================================================
시스템 명령어 사용
os.system('copy temp.py D:\\temp2.py')
=====================================================================================
python function argument, return type 
def train_minibatch(DQN: dqn.DQN, train_batch: list) -> float:


=====================================================================================
import random
random.randint(a,b) ===> a<= x <=b
random.randrange(a,b+1) ===> a<= x <=b
np.random.randint(a,b+1) ==> a<= x <=b 


=====================================================================================
os.system('color 4')   # ----> 이게 있어야 한다.
class bcolors:
    HEADER = '\033[1;30;95m'
    OKBLUE = '\033[1;31;94m'
    OKGREEN = '\033[1;32;92m'
    WARNING = '\033[1;33;93m'
    FAIL = '\033[1;34;91m'
    ENDC = '\033[1;35;0m'
    BOLD = '\033[1;36;1m'
    UNDERLINE = '\033[1;37;4m'

color = bcolors.OKGREEN
print ('hccho' , color + 'hi' + bcolors.ENDC, 1200.09 )


###########
color2num = dict(
    gray=30,
    red=31,
    green=32,
    yellow=33,
    blue=34,
    magenta=35,
    cyan=36,
    white=37,
    crimson=38
)

def colorize(string, color, bold=False, highlight=False):
    """
    Colorize a string.

    This function was originally written by John Schulman.
    """
    attr = []
    num = color2num[color]
    if highlight: num += 10
    attr.append(str(num))
    if bold: attr.append('1')
    return '\x1b[%sm%s\x1b[0m' % (';'.join(attr), string)

print('plain',colorize(msg, 'green', bold=False))
print('Bold', colorize(msg, 'green', bold=True))
print('highlight', colorize(msg, 'green', highlight=True))
print('Bold, highlight', colorize(msg, 'green', bold=True, highlight= True))
print('123hxdf')

=====================================================================================
# np.digitize: np.digitize( data, gird) ---> data에는 여러개가 들어가도 됨.   
# data[i]가 grid의 어떤 index에 대응되는지 찾아준다. 정확히는 data[i]를 초과하는 grid값의 index
# grid의 index가 0..n-1(size n)이면 return 되는 index는 0~n까지이다. grid index 범위를 넘어간다.

grid = np.array([0.0, 1.0, 2.5, 4.0, 10.0])
np.digitize([1.0,0.5,2.5], grid)  ---> array([2, 1, 3], dtype=int64)
# 1.0 --> grid의 1.0 < 2.5이므로 2.5=grid[2]에 해당하는 2


=====================================================================================
# Colab 파일 업로드
# local pc --> colab 파일 업로드
#  여러개 동시 선택 가능 해야 됨
from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))


=====================================================================================
def binary_to_array():
    # 1. bianry을  ---> Image를 통해 array
    # 2. file을 Image로 load
    # 3. binary를 tf.image.decode_jpeg
    # 1.2 결과는 동일. 3은 일치하지는 않는다.
    
    
    from PIL import Image
    import matplotlib.pyplot as plt
    import six
    
    
    imagePath = 'D:/OCR/deep-text-recognition-benchmark-master/demo_image/ABC마트.jpg'
    with open(imagePath, 'rb') as f:
        imageBin = f.read()
    
    buf = six.BytesIO()
    buf.write(imageBin)
    buf.seek(0)    
    img1 = Image.open(buf).convert('RGB')
    img1_array = np.array(img1)
    print(img1_array.shape)
    
    
    # Image를 이용하여 바로 읽기.
    img2 = Image.open(imagePath).convert('RGB')
    img2_array = np.array(img2)
    print(img2_array.shape)
    
    
    
    
    plt.subplot(1,2,1)
    plt.imshow(img1_array)

    plt.subplot(1,2,2)
    plt.imshow(img2_array)
    
    plt.show()
    
    
    print(np.allclose(img1_array,img2_array))
    

    # tensorflow 
    import tensorflow as tf
    
    x = tf.image.decode_jpeg(imageBin, channels=3)
    sess = tf.Session()
    xx = sess.run(x)   
    print(xx.shape)  # 값의 차이는 이다. 
    print(np.allclose(img1_array,xx))


=====================================================================================
from pydub import AudioSegment
sound = AudioSegment.from_wav("D:/SpeechRecognition/sample-kor.wav")
sound = sound.set_channels(1)
sound = sound.set_frame_rate(16000)
sound.export("D:/SpeechRecognition/sample-kor.flac",format = "flac")


=====================================================================================

try:
	x = sess.run([next_element["input_ids"],next_element["input_mask"],next_element["segment_ids"] ]) 
except Exception as ex:
	print("error message: ", ex)


=====================================================================================
import numpy as np
from IPython.lib.pretty import pprint

a = np.random.randn(1000,100)
print(a)

a = list(a)
pprint(a,max_seq_length=5)


=====================================================================================
> python setup.py install   ----> 다음과 같이 error발생

Traceback (most recent call last):
  File "c:\users\marketpoint\downloads\manimlib-0.1.11\manimlib-0.1.11\.eggs\pbr-5.5.0-py3.6.egg\pbr\core.py", line 96, in pbr
    attrs = util.cfg_to_args(path, dist.script_args)
  File "c:\users\marketpoint\downloads\manimlib-0.1.11\manimlib-0.1.11\.eggs\pbr-5.5.0-py3.6.egg\pbr\util.py", line 272, in cfg_to_args
    pbr.hooks.setup_hook(config)
  File "c:\users\marketpoint\downloads\manimlib-0.1.11\manimlib-0.1.11\.eggs\pbr-5.5.0-py3.6.egg\pbr\hooks\__init__.py", line 25, in setup_hook
    metadata_config.run()
  File "c:\users\marketpoint\downloads\manimlib-0.1.11\manimlib-0.1.11\.eggs\pbr-5.5.0-py3.6.egg\pbr\hooks\base.py", line 27, in run
    self.hook()
  File "c:\users\marketpoint\downloads\manimlib-0.1.11\manimlib-0.1.11\.eggs\pbr-5.5.0-py3.6.egg\pbr\hooks\metadata.py", line 26, in hook
    self.config['name'], self.config.get('version', None))
  File "c:\users\marketpoint\downloads\manimlib-0.1.11\manimlib-0.1.11\.eggs\pbr-5.5.0-py3.6.egg\pbr\packaging.py", line 858, in get_version
    version = _get_version_from_pkg_metadata(package_name)
  File "c:\users\marketpoint\downloads\manimlib-0.1.11\manimlib-0.1.11\.eggs\pbr-5.5.0-py3.6.egg\pbr\packaging.py", line 826, in _get_version_from_pkg_metadata
    pkg_metadata = email.message_from_file(pkg_metadata_file)
  File "C:\Anaconda3\lib\email\__init__.py", line 54, in message_from_file
    return Parser(*args, **kws).parse(fp)
  File "C:\Anaconda3\lib\email\parser.py", line 54, in parse
    data = fp.read(8192)
UnicodeDecodeError: 'cp949' codec can't decode byte 0xe2 in position 2512: illegal multibyte sequence
error in setup command: Error parsing C:\Users\MarketPoint\Downloads\manimlib-0.1.11\manimlib-0.1.11\setup.cfg: UnicodeDecodeError: 'cp949' codec can't decode byte 0xe2 in position 2512: illegal multibyte sequence


packaging.py", line 826   ---> pkg_metadata_file = open(filename, 'r') ===> pkg_metadata_file = open(filename, 'r',encoding='UTF8')
=====================================================================================
# 디렉토리를 생성날짜 별로 정렬해서, 가장 최근 디렉토리 찾기.

data_dir = '/home/hccho2/projects/KoELECTRA/finetune/ckpt'
all_dirs = os.listdir(data_dir)
all_dirs = [[d, os.stat(os.path.join(data_dir,d)).st_mtime] for d in all_dirs]
all_dirs = sorted(all_dirs,key= lambda x: x[1],reverse=True)
data_dir = os.path.join(data_dir,all_dirs[0][0])
data_files = glob(os.path.join(data_dir,'eval','*.txt'))

=====================================================================================
os.environ['USERPROFILE']     ====> 'C:\\Users\\BRAIN'

os.path.expanduser("~")    ===> 'C:\\Users\\BRAIN'


os.path.join(os.environ['USERPROFILE'], r'AppData\Local\Microsoft\Windows\Fonts\NanumGothic-Regular.ttf')

cmd 창에서는 
> echo %USERPROFILE%
> echo %PATH%
=====================================================================================
def create_directory(dir):
    if not os.path.exists(dir):
        os.makedirs(dir)


=====================================================================================


dict형의 앞부분만 보고 싶을 때....
{k: v for i, (k, v) in enumerate(my_dict.items()) if i < 5}

# list값을 key로 dict 만들기
dirs = 'yes no up down left right on off stop go'.split()
num_of_shorter = dict.fromkeys(dirs, 0)


=====================================================================================
하위 디렉토리 목록
dirs = [f for f in os.listdir(train_audio_path) if os.path.isdir(os.path.join(train_audio_path, f))]
dirs = glob.glob(os.path.join(train_audio_path,'*/'))  # 

=====================================================================================
x = np.array([3,5,1,4])
x[[False,True,False,True]]  # ===> [5,4] 


=====================================================================================
# 아래, 아래의 아래... 모든 디렉토리
dataset_path = r'D:\SpeechRecognition\speech_commands\speech_dataset'
count = 0
for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):
    if dirpath is not dataset_path:
        for f in filenames:
            if f.endswith('.wav'):
                label = dirpath.split('\\')[-1]
                fullpath = os.path.join(dirpath,f)
                print(i,count,label, fullpath)
                count += 1


=====================================================================================
# 1 level 아래 하위 디렉토리
import os
d = r'D:\SpeechRecognition\speech_commands\speech_dataset'
[d for o in os.listdir(d) if os.path.isdir(os.path.join(d,o))]


=====================================================================================
https://wikidocs.net/16073
class 상속

class Country:
    """Super Class"""

    def __init__(self, name,population, capital):
        self.name = name
        self.population = population
        self.capital = capital

    def show(self):
        print('국가 클래스의 메소드입니다.')
        print("국가의 이름은 {} 입니다. 국가의 인구는 {} 입니다. 국가의 수도는 {} 입니다.".format(self.name, self.population, self.capital))
class Korea(Country):
    """Sub Class"""

    def __init__(self, name,population, capital,color):
        #super(Korea,self).__init__(name,population,capital)
        super().__init__(name,population,capital)
        self.color = color
    def show(self):
        super().show()
        print("색:", self.color)


x = Korea('a',1000,'서울','red')
x.show()
=====================================================================================
labels = ['backward', 'bed', 'bird', 'cat']

labels.index('bird') # ---> 1  ----> list에서 index를 이용한 find. --> 가장 앞에 있는 index를 찾는다.

=====================================================================================
numpy array ...(ellipsis)
a = np.array([[1.,2.],[3,4]])
b = a

a[...] = np.array([[10.,20.],[30,4]])  # a, b모두 변한다.
=====================================================================================


=====================================================================================


=====================================================================================


=====================================================================================


=====================================================================================


=====================================================================================


=====================================================================================


=====================================================================================


=====================================================================================


=====================================================================================


=====================================================================================


