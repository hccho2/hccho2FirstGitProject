python 3.6설치

https://repo.continuum.io/archive/index.html
Anaconda3-5.2.0-Windows-x86_64.exe  ---> python 3.6
=============================
pydev 수동 설치:
- features와 plugins 파일들을 위치에 복사한다.
- java는 설치해도 되지만, eclipse아래에 jre디렉토리 만들고, 복사해도 
- eclipse 실행 후, windows-preferences-PyDev-Interpreters-Python Interpreter - QuickAuto-Config

===========================================================================
venv로 가상환경 만들기

1. 가상환경을 만들 디렉토리를 만들어 이동한다.
2. python -m venv 가상환경이름   --> 현재 디렉토리 아래에 가상환경 이름을 가진 directory가 만들어진다.
3. 가상환경이 만들어지 directory로 이동한다.
4. xxxx>     Scripts\activate
5. 종료하려면, deactivate
=====================================================================
eclipse: Windows-Preference-PyDev-Interpreters-Python Interpreter  ---> 복수로 등록 가능
예: 
python     C:\Anaconda\python.exe
tfcpu      C:\Anaconda\hccho-virtual\tfcpu\Scripts\python.exe

이렇게 등록한 2개는 각각의 project에서 선택가능하다.  project의 properties - PyDev-Interpreter/Grammar - Interpreter 에서 선택하면 된다.

=====================================================================
> pip download 
=====================================================================
import skimage.io as io   --- error --- pip install로는 안되고,
pip install --upgrade scikit-image
=====================================================================
Eclipse에 이미 만들어져 있는 project 추가: New -> Project -> General -> Project --> 폴더 선택 & 이름 입력

=============================

import sys
sys.path.append("../")   <--- 코드내에 추가
sys.path.append("D:\\hccho\\im2txt\\im2txt")

sys.path.insert(0,'D:\\hccho\\ML\\PythonCode\\StackGAN-master')  <--- 코드내에 추가
또는 eclipse project properties에서 Resource-Linked Resources에서 path를 등록하면 
=====================================================================
방법은 단순합니다.

- cuda 9.0 + cudnn 7.1 + tensorflow 1.8
- cuda 8.1 + cudnn 6.0 + tensorflow 1.3

(cuda 8.0 다운받으러 가면, 8.0은 없고 8.1만 있음)

일단 
- cuda 9.0 + cudnn 7.1 설치 -> C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0
- cuda 8.1 + cudnn 6.0 설치 -> C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0

설치 후, 환경변수 path에 2개 디렉토리 모두 등록

base에 tensorflow-gpu 1.8 설치, 가상환경(저는 venv사용)에 tensorflow-gpu 1.3 설치

이렇게 하면 2가지 모두 잘 작동합니다.

=====================================================================


num_batch = int(max_train/batch_size) # 1epoch에 필요한 반복

for i in range(num_epoch):
    for j in range(num_batch):
	.
	.
	.
        if j % show_every== 0:
            print('(Iteration %d / %d, Epoch %d / %d) loss: %f' % (i*num_batch+j, num_epoch*num_batch, i, num_epoch, loss_xxx)

=====================================================================

np.set_printoptions(threshold=np.nan)  <--- 모든 data 다 표시
np.set_printoptions(precision=4)  <--- 유효숫자 표시
np.set_printoptions(suppress=True) <----- e없이 표시

np.set_printoptions(suppress=True, formatter={'float_kind':'{:5.3f}'.format}, linewidth=130)
====================================================================
import ctypes  # An included library with Python install.
def Mbox(title, text, style):
    ctypes.windll.user32.MessageBoxW(0, text, title, style)
====================================================================
np.shape ==> (n1-axis=0,n2-axis=1,n3-axis=2,...)
np.sum(x, axis=n) ==>  axis n 이 없으짐
===================================================================
np.squeeze(x) <== Remove single-dimensional entries from the shape of an array
np.expand_dims <== Insert a new axis, corresponding to a given position in the array shape
===================================================================
a=[1,1,2,2]
a= list(map((lambda x: x*x),a))
===================================================================
a=np.array([1,2,3,4,5,4,3,2,10]
b = a[a<5]  # numpy array이기 때문에 가능

# list comprehension
a=[1,2,3,4,5,4,3,2,10]
b = [ x*10 for x in a if x< 5]

y = [-1 if a==0 else 1 for a in y]
z = [-1 for a in y if a==1]
================================================
x = np.arange(-2, 3)
x.ravel()[np.flatnonzero(x)]  # Use the indices of the non-zero elements as an index array to extract these elements:
===================================================================
# sting ==> float변환
a = [['1.2','2.33'],['1.2','2.33']]
b = np.array(a,dtype=np.float32)

# numpy array ==> list
c = b.tolist()
===================================================================
A[[0,1,2],[0,0,1]] = [1,2,7]   #numpy array A[0,0],A[1,0],A[2,1]에 각각 1,2,7


===================================================================
# singular value of a ~ sqrt(eigenvalue) of (a.T)a  or a(a.T)
# data matrix a의 평균을 0으로 맞추고 나면, SVD는 PCA의 일반화. 
# SVD는 a.T.dot(a)를 계산하는 과정에서의 수치적인 손실을 줄일 수 있어 더 안정적이다.



# np.linalg의 첫번째  return  U의 열vector가 eigenvector에 해당함.

import contextlib

@contextlib.contextmanager
def printoptions(*args, **kwargs):
    original = np.get_printoptions()
    np.set_printoptions(*args, **kwargs)
    try:
        yield
    finally: 
        np.set_printoptions(**original)


import numpy as np
np.set_printoptions(threshold=np.nan)
#a = np.random.randint(10, size=(9, 6))
a =np.array([[0, 9, 7, 9, 1, 6, 7],
       [2, 3, 7, 8, 9, 6, 15],
       [2, 3, 4, 5, 9, 4, 13],
       [5, 8, 0, 3, 9, 5, 14],
       [7, 9, 9, 8, 4, 1, 5],
       [2, 7, 8, 2, 0, 0, 0],
       [8, 7, 0, 4, 8, 3, 12],
       [9, 2, 3, 8, 3, 0, 3],
       [6, 6, 2, 0, 9, 0, 9]])


#a =np.array([[5,-7,7],[4,-3,4],[4,-1,2]])
aa = a.T.dot(a)  # covariance matrix of a
w,z = np.linalg.eig(aa)  # z의 열벡터가 eigenvector

bb = a.dot(a.T)
ww,zz = np.linalg.eig(bb)  # zz의 열벡터가 eigenvector

U, s, V = np.linalg.svd(a, full_matrices=True) # V의 행벡터가 aa의 eigenvector. vector들 간의 부호가 뒤죽박죽.
# V의 행벡터가 aa의 eigenvector. vector들 간의 부호가 뒤죽박죽. 즉 z.T ~ V, 행들의 부호 때문에 잘 봐야함. rank 갯수 까지만 유효
# U의 열벡터가 bb의 eigenvector. zz.T ~ U.T. rank 갯수까지 유효


UU, ss, VV = np.linalg.svd(a, full_matrices=False) # "numerical recipes" 는 False에 해당하는 것을 구현

print(U.shape,s.shape,V.shape)
print(UU.shape,ss.shape,VV.shape)



with printoptions(precision=3, suppress=True):
    
    
    # spectral decomposition은 eigenvalue의 정의에 의해 쉽게 증명가능
    print('eigen decomposition = spectral decomposition', z.dot(np.diag(w)).dot(z.T) - aa)  
    
    # enginvalue 비교
    print('eigenvalue 비교',np.sqrt(w) - s)
    print('U.dot(U.T)',U.dot(U.T))
    print('UU.dot(UU.T)',UU.dot(UU.T))   # Identity 안됨
    print('UU.T.dot(UU)',UU.T.dot(UU))
    print('V.dot(V.T)', V.dot(V.T))
    print('VV.dot(VV.T)', VV.dot(VV.T))
    
    # full matrix는 padding을 해야 복원
    print(U.dot(np.pad(np.diag(s),[(0,2),(0,0)],'constant')).dot(V))
    # reduced form에서는 그냥 곱하면 됨
    print(UU.dot(np.diag(ss)).dot(VV))
    
    
    r = np.min(a.shape)
    print('thin SVD')
    print(U[:,:r].dot(np.diag(s[:r])).dot(V[:r,:]))
    print(UU[:,:r].dot(np.diag(ss[:r])).dot(VV[:r,:]))   
    
    
    # rank을 이용하여 ...
    r= np.linalg.matrix_rank(a)
    print('compact SVD')
    print(U[:,:r].dot(np.diag(s[:r])).dot(V[:r,:]))
    print(UU[:,:r].dot(np.diag(ss[:r])).dot(VV[:r,:]))
    
    
    r = 5 # rank 보다 작게 잡아, demension reduction을 할 수 있다.
    print('truncated SVD')
    print(U[:,:r].dot(np.diag(s[:r])).dot(V[:r,:]))
    print(UU[:,:r].dot(np.diag(ss[:r])).dot(VV[:r,:]))    

    # 행 축소
    r=4
    print('row reduction')
    print(U[:,:r].T.dot(a))

    # 열 축소
    r=3
    print('col reduction')
    print(a.dot(V[:r,:].T))

    
=====================================================================================
def f(x):
    return x+10

# make another list from a list
A = [1,2,3,4]
A2=[[1,2],[3,4],[5,6]]
#B = [x*10 for x in A]
#B = [f(x) for x in A]

#B = list(map(lambda x: x*10,A))
B = list(map(f,A))

df = pd.DataFrame(A2, columns=['age','age2'])
df['age']= df['age'].apply(f)
=====================================================================================
# DataFrame은 dict형으로 만들거나,  List에서 칼럼명을 지정해서 만들 수 있다.
df = pd.DataFrame({'Name':['C','K','P'],'age':[34,53,25]})


A=[[2,3,4],[3,3,5],[5,63,4],[3,4,5]]
A1=['a1','a2','a3']
A2=['x1','x2','x3','x4']
df2=pd.DataFrame(data=A,index=A2,columns=A1)

df3 = df2[['a3','a2']]  # 일부 칼럼만 가져오기
df3.columns = ['XX1','XX2']


======================
A = np.array([[13,24,3],[10,20,10],[100,1,1]])
print(A)
df2 = pd.DataFrame(A[1:,1:],columns=A[0,1:],index =A[1:,0])
print(df2)

=====================

모든 data출력
pandas.set_option('display.max_columns', None,'display.max_rows', None)

#Pivot
mydatapd = pd.DataFrame(mydata,columns=['A','B','C'])
mydatapd = mydatapd.pivot(index ='A',columns='B',values='C')

=====================================================================================
import pickle  # from six.moves import cPickle as pickle 도 가능
var1 = xxx
var2 = xxx
var3 = xx

with open('test.txt','wb') as f:
	pickle.dump(var1,f)
	pickle.dump(var2,f)
	pickle.dump(var3,f)



덤프(dump)한 순서대로 로드(load)된다.
 
with open('test.txt','rb') as f:
	data1=pickle.load(f)
	data2=pickle.load(f)
	data3=pickle.load(f)
=====================================================================================
with open('class_info.pickle','rb') as f:
	data1=pickle.load(f,encoding='latin1')
=====================================================================================
dict형으로 변수들을 묶어서 한번에 쓰고, 한번에 읽어올수 있다.
파일을 열때 'b'(binary)로 해야함.
with open('data.pickle', 'wb') as f:
    pickle.dump(data, f)

with open('data.pickle','rb') as f:
    data1=pickle.load(f)
=====================================================================================
# 다음과 같이 열어야 하는 경우도 있음.
from sklearn.externals import joblib
clf = joblib.load('meta.pkl')
=====================================================================================
# save to file. (1d, 2d array only)
np.savetxt("foo.txt", X1, delimiter=",")
=====================================================================================
#simple 파일 
values = ['1', '2', '3']
with open("file.txt", "w") as output:
    for i in values:
        output.write(str(i)+'\n')
=====================================================================================
np.random.standard_normal(size=(2,3))
d = np.array(100 * np.random.standard_normal(size=(2,3)),dtype=np.int16)/100
=====================================================================================
a = "123456789"
print("a[:]: ", a[:])  #123456789
print("a[::]: ", a[::])  #123456789
print("a[::3]: ", a[::3]) #147
print("a[::-1]: ", a[::-1]) #987654321

================================================
# 역순으로 for loop
for t in np.arange(5)[::-1]:
    print(t)

# reversed
for t in reversed(range(5)):
    print(t)

================================================
mat = [[1, 2, 3], [4, 5, 6]]
A = list(zip(*mat))   # [(1, 4), (2, 5), (3, 6)]
B= list(np.array(A))
print(B)   # [array([1, 4]), array([2, 5]), array([3, 6])]
C = np.array(A).tolist()
print(C)  # [[1, 4], [2, 5], [3, 6]]
=========================================================

a = ["Code", "mentor", "Python", "Developer"]
print (" ".join(a))  #  Code mentor Python Developer

=====================================================================================
datetime.date(2017,7,17)+datetime.timedelta(days=4)
=====================================================================================
# list, numpy 모두 그냥 할당하면 같은 곳 참조, copy를 해야

a = np.array([2,3,4])
b=a  # b=a.copy()
b[0] = 10

print(a,b)  #[10  3  4] [10  3  4]


a = [2,3,4]
b=a   # b=a.copy()
b[0] = 10

print(a,b)  #[10  3  4] [10  3  4]
=====================================================================================
from IPython.display import display, Math, Latex
display(Math(r'F(k) = \int_{-\infty}^{\infty} f(x) e^{2\pi i k} dx'))
=====================================================================================
경과시간

import time
s=time.time()
...
e=time.time()

print(e-s,"sec")
=====================================================================================
A = np.array([[1,2,0,0,0],[2,3,5,0,0],[0,1,3,2,0],[0,0,1,2,3],[0,0,0,2,1]])
B = np.array([2,3,1,0,1]).T

X = np.linalg.solve(A,B.T)
print(X, A.dot(X))
=====================================================================================
#이진수 만들기
import numpy as np
A = np.array([range(5)],dtype=np.uint8).T
B = np.unpackbits(A,axis=1)
=====================================================================================
"""
mydata3.txt
3
5
1.2,3,4,5,6
33,1,2,3,4
2,3.4,5.5,6,6


"""
import numpy as np

file = open("mydata3.txt")
line  = file.readline()
dimX = int(line)

line  = file.readline()
dimY = int(line)

lines = file.readlines()
lines = ','.join(lines)
lines = lines.replace('\n','')
data = np.fromstring(lines,sep=',',dtype=np.float).reshape(dimX,dimY)
print(data)
=====================================================================================
import numpy as np

A ={'a':[1,2,3],'b': [3,4,5,3,6,6,4]}  # dict

np.save('test.npy',A)

a = np.load('test.npy')  # numpy.ndarray
b = a.item()  # 저장했던 dict. 이렇게 해야, b가 a와 같은 dict가 된다.
=====================================================================================
A ={'a':[1,2,3],'b': [3,4,5,3,6,6,4]}  # dict
np.savez('test.npz',**A)  # 이렇게 저장해야, 다시 load했을 때, dict형으로 복원이 편한다.
data = np.load('test.npz')  # dict(data) --> dict형으로 쉽게 변환되고, 변환하지 않아도 dict 처럼 사용가능.
단, dict로 만들어진 A속에 dict형이 있으면 잘 복원되지 않는다. dict를 포함하고 있는 경우는 pickle로 저장하는 것이 좋다.

=====================================================================================
# npy는 numpy array이지만, npz는 dict형에 가깝다.
a = np.load('D:\\hccho\\data\\LJ001-0001-audio.npy')  # numpy.ndarray
b = np.load('D:\\hccho\\data\\LJ001-0001-mel.npy')  # numpy.ndarray

c = np.load('D:\\hccho\\TACOTRON\\multi-speaker-tacotron-tensorflow-master\\datasets\\son\\data\\NB10584578.0000.npz') #numpy.lib.npyio.NpzFile
print(c.keys())  # --> ['linear', 'mel', 'tokens', 'loss_coeff', 'allow_pickle']

=====================================================================================
# 파일 한줄씩 읽어, list에 저장
with open('wnids.txt', 'r') as f:
    A = [x.strip() for x in f]
=====================================================================================
import pandas as pd

filename = 'D:\\test.txt'
data = {}
data["review"] = []
with open(filename, "r", encoding='utf-8') as file:
    data["review"].append(file.read())

    
with open(filename, "r", encoding='utf-8') as file:
    A = [x.strip() for x in file]
    
"""
Bromwell High is a cartoon comedy.
It ran at the same time as some 
other programs about school life, 
such as "Teachers".
 My 35 years in the teaching profession lead me to believe that Bromwell



==>
data
{'review': ['Bromwell High is a cartoon comedy.\nIt ran at the same time as some \nother programs about school life, \nsuch as "Teachers".\n My 35 years in the teaching profession lead me to believe that Bromwell\n\n\n']}

A
['Bromwell High is a cartoon comedy.',
 'It ran at the same time as some',
 'other programs about school life,',
 'such as "Teachers".',
 'My 35 years in the teaching profession lead me to believe that Bromwell',
 '',
 '']

=====================================================================================
# loadtxt, genfromtxt는 같은 기능이지만, 
# genfromtxt는 missing data를 다룰 수 있는 다양한 옵션이 있다.
# numpy.loadtxt: equivalent function when no data is missing.


mydata = np.genfromtxt('mydata2.txt',delimiter=',',dtype=np.float32)
mydata = np.loadtxt('mydata2.txt', delimiter=',', dtype=np.float32)    
    
=====================================================================================
import numpy as np
import pandas as pd
import datetime 

"""
2005-01-03    452500     453000     446000     451000     0.015     0.000     0.350      0.30     41750     41750     41200     41200     0.015     0.000     0.350 
2005-01-04    450000     451000     446000     447000     0.015     0.000     0.350      0.30     41450     41650     41000     41450     0.015     0.000     0.350 
2005-01-05    440000     443000     436500     443000     0.015     0.000     0.350      0.30     41200     41500     41150     41450     0.015     0.000     0.350 
2005-01-06    439000     445500     435000     435000     0.015     0.000     0.350      0.30     41650     42800     41250     42200     0.015     0.000     0.350 
2005-01-07    441000     441500     435500     440500     0.015     0.000     0.350      0.30     42200     42600     41550     41550     0.015     0.000     0.350 

"""

data = pd.read_csv("inputdata.dat", sep="\t",header = None ,index_col =None, names=['date','start1','high1','low1','close1','R1','Div1','Vol1','Rho','start2','high2','low2','close2','R2','Div2','Vol2'])

data['date'] = pd.to_datetime(data['date']).apply(pd.Timestamp.date)
data=data.set_index('date')


dd = datetime.date(2005,1,5) + datetime.timedelta(days=6)
b = data.loc[dd]['start1']
a = data.ix[0]
print(b,a)


=====================================================================================
random 선택

N = 100
A = np.arange(N)
choice = np.random.choice(N,10)  # 중복있음
choice = np.random.choice(N,10, replace=False)

B = A[choice]


===
a = np.random.rand(3) # 3개 중에 선택
a = a/np.sum(a) # 합이 1이 되로록(확률)

# method 1
i = int(np.searchsorted(np.cumsum(a),np.random.rand(1)) # 1개 선택

# method 2
j = np.random.choice(len(a),1,a.tolist())  # 1개 선택


=============================================
import numpy as np
import random
from collections import deque  #collections에는 다양한 자료형이 있다.
A = deque(maxlen=100)

A.append([3.5,1])
A.append([4.5,5])
A.append([5.5,2])
A.append([6.5,1])
A.append([7.5,3])  # deque([[3.5, 1], [4.5, 5], [5.5, 2], [6.5, 1], [7.5, 3]])

B = random.sample(A,2)  # [[4.5, 5], [5.5, 2]]
C = np.random.choice(A,2)  # ==> error. must be 1-dimensional


=============================================
Shuffle
s = np.arange(A.shape[0])
np.random.shuffle(s)

A1 = A[s]
B1 = A[s]
=====================================================================================
import numpy as np

#처음에 data 없이 빈공간만 shape에 맞게 만들기
a = np.empty(0).reshape(0,3,2)
b= np.array([[[1.2,2],[3,4],[5,6]]])
c = np.concatenate((a,b),0)
=====================================================================================
import argparse

parser = argparse.ArgumentParser(description='Easy Implementation of DCGAN')

#다음과 같이 하면, -h(help)에서 default argument 값도 보여준다.
parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)



# parameters
parser.add_argument('datasets', metavar='N', type=str, nargs='+', choices=['celebA', 'lsun', 'mnist'],
           help='name of dataset to download [celebA, lsun, mnist]')
# 위의 경우와 같이 -- 없이 'datasets'만 있는 경우, argument값만 넘겨야 한다.
# nargs='+' ==> 여러개의 argument가 list로 들어간다.


parser.add_argument('--filelist', type=str, default='filelist.txt')
parser.add_argument('--out_dir', type=str, default='./output', help="where to put output files")
parser.add_argument('--epochs', type=int, default=10)
parser.add_argument('--batch_size', type=int, default=32)
parser.add_argument('--batch_size2', required=True, choices=["aa","bb"])   <----- required=True 항목이 빠지면, usage를 출력하면서 끝난다.

# 옵션에 따라 하나의 parameter 설정
parser.add_argument("--flip", dest="flip", action="store_true", help="flip images horizontally")  
#  ---> action="store_true"  ==> default로 False. 반면 action="store_false"  ==> True
parser.add_argument("--no_flip", dest="flip", action="store_false", help="don't flip images horizontally")
parser.set_defaults(flip=True)

args = parser.parse_args()
filelist_dir = args.filelist
output_dir = args.out_dir

total_epoch = args.epochs
batch_size = args.batch_size

print(filelist_dir, output_dir, total_epoch,batch_size  )

> python  zzz.py -h   ==> help 출력
=====================================================================================
# lbfgs를 default로 true로하고, --adam 을 argument로 넣으면, lbfgs가 false
parser.add_argument("--adam",dest='lbfgs',help="True=lbfgs, False=Adam", action="store_false")
parser.set_defaults(lbfgs=True)
=====================================================================================
import argparse
parser=argparse.ArgumentParser()
parser.add_argument('-auto', action='store_false', )
parser.add_argument("--max_epochs", type=int, default=100, help="number of training epochs")
args=parser.parse_args()
print(args)
print(vars(args))  # 내장함수 vars를 이용하여 dict형으로 변환


=====================================================================================
parser = argparse.ArgumentParser()
parser.add_argument('--batch_size', default=100, type=int, help='batch size')
parser.add_argument('--train_steps', default=1000, type=int,help='number of training steps')


#args = parser.parse_args()

args = parser.parse_args(sys.argv[1:])  # 새로운 argument추가는 불가. 이미 정의된 argument update가능

=====================================================================================
parser = argparse.ArgumentParser()
args = parser.parse_args()

args.num_hidden = 10
args.num_epoch = 20
print(args)


=====================================================================================
flags = tf.app.flags
이 함수는 argparse 모듈과 같은 역할을 합니다. argparse보다 나은 점은 저가 볼 때는 굳이 argparser를 import 할 필요 없이 아래와 같이 추가만 하면 됩니다.

flags = tf.app.flags
flags.DEFINE_integer("epoch", 25, "Epoch to train [25]")
flags.DEFINE_string("sample_dir", "samples", "Directory name to save the image samples [samples]")
flags.DEFINE_boolean("is_crop", False, "True for training, False for testing [False]")
FLAGS = flags.FLAGS

if not os.path.exists(FLAGS.checkpoint_dir):
    os.makedirs(FLAGS.checkpoint_dir)

flags에 tf.app.flags 를 통해 객체를 저장하고 DEFINE_integer나 DEFINE_string 을 통해 아래 argparse와 같은 역할을 할 수 있습니다

=====================================================================================
Examples = collections.namedtuple("Examples", "paths, inputs, targets, count, steps_per_epoch")
=====================================================================================
image 읽기

img = skimage.io.imread(path)  ==> 정수 data
resized_img = skimage.transform.resize(crop_img, (img_size, img_size))  #정수 data image가 넘어와도 float로. preserve_range=True(정수형태지만, type은 float)

skimage.io.imshow(img)
plt.show()
======
im = scipy.misc.imread   ==> 정수 data
im = scipy.misc.imresize(im, self.resize)

scipy.misc.imsave(save_path, im)
=====================================================================================
import os, glob
a = os.path.join("../tensorflow-style-transfer-master","images", "*.jpg") #string을  \로 이어  path를 만든다.
b = glob.glob(a) # wild card를 풀어  filename list를 만든다.
=====================================================================================
input_dir = "D:\\hccho\\CycleGAN-TensorFlow-master\\data\\apple2orange\\testA"
x = os.scandir(input_dir)

for i in x:
    print(i.path)
=====================================================================================
import gzip,os
import numpy as np
import skimage.io
import scipy.misc
import matplotlib.pyplot as plt

data_dir = 'D:\hccho\ML\PythonCode\CommonDataset\mnist'
fd = os.path.join(data_dir,'train-images-idx3-ubyte.gz')
with gzip.open(fd, 'rb') as f:
    loaded = np.frombuffer(f.read(), np.uint8, offset=16)
    trX = loaded.reshape((60000,28,28,1)).astype(np.float)  


skimage.io.imshow(np.squeeze(trX[0]/255.0))
plt.show()
skimage.io.imshow(np.squeeze((trX[0]/255.0 +1)/2))
plt.show()


plt.imshow(np.squeeze(trX[0]/255.0))
plt.show()
plt.imshow(np.squeeze((trX[0]/255.0 +1)/2))


#scipy.misc.imsave("a.jpg",np.squeeze(trX[0]/255.0))  # 0~1
#scipy.misc.imsave("b.jpg",np.squeeze((trX[0]/255.0 +1)/2)) 0.5~1

img1 = skimage.io.imread("a.jpg")
img2 = skimage.io.imread("b.jpg")
=====================================================================================
from PIL import Image
import os, glob

#image_files = glob.glob("./*.png")
image_files = glob.glob("../DCGAN-tensorflow-master/samples/test*.png")


images = [Image.open(f) for f in image_files]

gif = images[0]
gif.save(fp="./output.gif", format='gif', save_all=True, append_images=images[1:])
print(Image.open("./output.gif").n_frames)
=====================================================================================
import skimage.io
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets('D:\hccho\CommonDataset\mnist', one_hot=True)
inputs = mnist.train.images
labels = mnist.train.labels
n  = 14
skimage.io.imshow(inputs[n].reshape(28,28))
print(labels[n])
=====================================================================================
# image file 읽어와 보여주기
x = ['a.jpg','b.jpg','c.jpg','d.jpg']

img = imread(x[1])
plt.subplot(2,1,1)
plt.imshow(img)


img = imread(x[2])
plt.subplot(2,1,2)
plt.imshow(img)

plt.show()


=====================================================================================
def change_image_format():
    import os, glob
    a = os.path.join("D:\hccho\StackGAN-hccho\StcakGAN-Result", "*.png") #string을  \로 이어  path를 만든다.
    b = glob.glob(a) # wild card를 풀어  filename list를 만든다.
    
    
    for f in b:
        image = Image.open(f)
        image.save(f[:f.find('png')] + 'jpg')

=====================================================================================
# numpy image concat
# a: shape =(5, 256, 256, 3)

np.concatenate(a,axis=0)   ==>    (1280, 256, 3)  <---- a[0],a[1],a[2],a[3],a[4] 가 axis = 0으로 concat된다.
np.concatenate(a,axis=1)   ==>    (256, 1280, 3)
np.concatenate(a,axis=1)   ==>    (256, 256, 15)
=====================================================================================
img_path = "cat.jpeg"

im = plt.imread(img_path)
h,w,c = im.shape
h1 = w1 = 512
img_raw = tf.io.read_file(img_path)
img_tensor = tf.reshape(tf.image.decode_image(img_raw),im.shape)

img_upsampled = tf.image.resize_images(img_tensor,size=(h1,w1),method=1)   #BILINEAR = 0, NEAREST_NEIGHBOR = 1, BICUBIC = 2, AREA = 3



sess = tf.Session()
x = sess.run(img_tensor)
x_upsampled = sess.run(img_upsampled)

fig = plt.figure()
fig.suptitle("Upsampling", fontsize=16)
ax = plt.subplot("121")
ax.set_title("Origin")

ax.imshow(x,extent=[0,w,0,h])
ax.set_aspect('equal',anchor ='SW')



ax = plt.subplot("122")
ax.set_title("Resize")

ax.imshow(x_upsampled,extent=[0,h1,0,w1])
ax.set_aspect('equal',anchor ='SW')


plt.axes
plt.show()



=====================================================================================
print(os.listdir("../"))     <---모든 디렉토리

=====================================================================================
#list 원소 모두 곱하기
from functools import reduce

A = [2,3,5]
result = reduce(lambda x, y: x * y, A)
print(result)

#np.prod로 하면 더 간단함.
np.prod(A)
=====================================================================================
#array 초기화 
empty,empty_like, ones, ones_like, zeros, zeros_like, full, full_like
x = np.arange(6)
x = x.reshape((2, 3))
x = np.zeros_like(x)



# array random 초기화: rand, randn, ranint, random
A = np.random.rand(2,3,4)  # 같은 기능  np.random.random((2,3,4))
A = np.random.randn(2,3,4) # 표준정규분포, 비표준정규분포는 sigma * np.random.randn(...) + mu
A = np.random.randint(10, size=(9, 6))


random sample n개 뽑기
B = np.random.normal(1,2,10)
=====================================================================================
A.shape + (1,)
(1,) + A.shape
=====================================================================================
from functools import partial

=====================================================================================
class HC:
    def __init__(self,a):
        self._a = a
    @property
    def x(self):
        return self._a
    @x.setter 
    def x(self,xx):
        self._a = xx
        
A = HC(4)
A.x = 3
print(A.x)

=====================================================================================
getattr
=====================================================================================
print("float: {:0.8f}, int: {:10d}".format(2.34, 45))  # float: 2.34000000, int:         45
print("{:10}".format('test')) # left align             test      
print("{:>10}{:>10}".format('test',123)) # right align #      test       123
print("{:>10}{:06d}".format('test',123)) # fill 0, 6digit #       test000123
print("{:06.2f}".format(3.14156))   #003.14
print("{:06}".format(35))  # 000035
print("{:,.2f}".format(1233456.8934))  # 1,233,456.89
print("{:.2f}".format(3.25148))  # 3.25
=====================================================================================
import collections

#with codecs.open(input_file, "r", encoding=self.encoding) as f:
#    data = f.read() # data: <class 'str'>


data = 'abcd aaa bb d fff'
counter = collections.Counter(data) # Counter({' ': 4, 'a': 4, 'b': 3, 'c': 1, 'd': 2, 'f': 3})

x = sorted(counter.items()) # [(' ', 4), ('a', 4), ('b', 3), ('c', 1), ('d', 2), ('f', 3)]
y = sorted(counter.items(),key=lambda x: -x[1]) #[('a', 4), (' ', 4), ('b', 3), ('f', 3), ('d', 2), ('c', 1)]
z = sorted(counter.items(),key=lambda x: x[1])  #[('c', 1), ('d', 2), ('b', 3), ('f', 3), ('a', 4), (' ', 4)]


chars, _ = zip(*y) # alphabet 만 
vocab = { ch:i for i,ch in enumerate(chars) } # alphabet에 숫자에 대응 부여
tensor = np.array(list(map(vocab.get, data))) # data를 숫자로 변환
=====================================================================================
# dict 정렬
vocab = {'a': 3,'b':7, 'c': 1}
X =sorted(vocab, key=vocab.get, reverse=True)  #내림차순 list
Y =sorted(vocab, key=vocab.get, reverse=False) #오름차순 list
=====================================================================================

def change_one_hot_label(X,n_dim=10):
    X = X.astype(np.int32)
    T = np.zeros((X.size, n_dim))
    for idx, row in enumerate(T):
        row[X[idx]] = 1

    return T 

print(change_ont_hot_label(np.array([2,3,2]),5))
[[ 0.  0.  1.  0.  0.]
 [ 0.  0.  0.  1.  0.]
 [ 0.  0.  1.  0.  0.]]
=====================================================================================
one-hot
y =[2,3,4]
x = np.zeros((3,10))
x[np.arange(3),y]=1
=====================================================================================
# 특정값을 가지는 array의 index 추출(찾기)
A = np.array([2,3,2,2,1,5])
B = np.array([1,3,4,2,2,5])
ind_A = np.flatnonzero(A == 2)
ind_B = np.flatnonzero(A == B)
=====================================================================================
def multiply(*args):
    z = 1
    for num in args:
        z *= num
    print(z)

multiply(4, 5)
multiply(10, 9)
multiply(2, 3, 4)
multiply(3, 5, 10, 6)

def print_kwargs(**kwargs):  # dict형으로 처리
        print(kwargs)

print_kwargs(kwargs_1="Shark", kwargs_2=4.5, kwargs_3=True)

=======

def safe_division_d(number, divisor, **kwargs):

ignore_overflow = kwargs.pop(‘ignore_overflow’, False)

ignore_zero_div = kwargs.pop(‘ignore_zero_division’, False)

if kwargs:

raise TypeError(‘Unexpected **kwargs: %r’ % kwargs)


pop 메서드로 kwargs 딕셔너리에서 원하는 키워드 인수를 꺼낸다. 키가 없을 때의 기본값은 pop 메서드의 두번째 인수로 지정한다. 
마지막으로 kwargs에 더는 남아 있는 키워드가 없음을 확인하여 호출하는 쪽에서 올바르지 않은 인수를 넘기지 않게 한다.


=====
=====================================================================================
# grid
#xx, yy = np.meshgrid(np.arange(-1,1, 1), np.arange(-2, 2, 1))
xx, yy = np.meshgrid(np.linspace(4,-4,10),np.linspace(4,-4,10))

z = np.c_[xx.T.ravel(), yy.T.ravel()]

array([[-1, -2],[ 0, -2],[-1, -1],[ 0, -1],[-1,  0],[ 0,  0],[-1,  1],[ 0,  1]])
=====================================================================================
grid = np.mgrid[0:2, 0:3].reshape(2,-1).T
=====================================================================================

import os
filename='E:\\dir1\\dir2\\aa.txt'
os.path.dirname(filename)  # 'E:\\dir1\\dir2'
os.path.abspath(filename)  # 'E:\\dir1\\dir2\\aa.txt'
os.path.basename(filename)  # 'aa.txt'
os.path.splitext(filename)  ==> ('E:\\dir1\\dir2\\aa','txt')  이걸 이용해서 확장자 변경가능
os.path.splitext(os.path.basename(filename))[0]  # ('aa', '.txt')
os.path.join(os.path.dirname(filename), 'aaaa.dat')  # 'E:\\dir1\\dir2\\aaaa.dat'


# all sub directory
dir = 'D:\hccho\speech-recognition\speech_commands\speech_dataset'
all_subdir = [x[0] for x in os.walk(dir) if x[0] != dir]

=====================================================================================
import re

_WORD_SPLIT = re.compile(b"([.,!?\"':;)(])")
def basic_tokenizer(sentence):
    """Very basic tokenizer: split the sentence into a list of tokens."""
    words = []
    for space_separated_fragment in sentence.strip().split():
        if isinstance(space_separated_fragment, str):
            word = str.encode(space_separated_fragment)
        else:
            word = space_separated_fragment  
        words.extend(re.split(_WORD_SPLIT, word))
    return [w.decode('utf-8') for w in words if w]
 
s = 'Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.'
x = basic_tokenizer(s) # ['Can', 'we', 'make', 'this', 'quick', '?', 'Roxanne', 'Korrine', 'and', 'Andrew', 'Barrett', 'are', 'having', 'an', 'incredibly', 'horrendous', 'public', 'break-', 'up', 'on', 'the', 'quad', '.', 'Again', '.']

y=[w.strip() for w in s.split(' ') if w] #['Can', 'we', 'make', 'this', 'quick?', 'Roxanne', 'Korrine', 'and', 'Andrew', 'Barrett','are', 'having', 'an', 'incredibly', 'horrendous', 'public', 'break-', 'up', 'on', 'the', 'quad.', 'Again.']

=====================================================================================
# simple graph
import numpy as np
import matplotlib.pyplot as plt
def f(x,a):
    return (0.5*(1+a))* x + (0.5 * (1 - a)) * np.abs(x)

x = np.linspace(-3,3,100)
y= f(x,0.2)

plt.figure(figsize=(6, 6))
plt.plot(x, y, c=[1, 0.2, 0.05], linewidth=8)  # c=[1, 0.2, 0.05] <--RGB color
plt.xlim([-3, 3])
plt.ylim([-3, 3])
plt.show()
=====================================================================================
# simple scatter
def g(p):
    r = np.sqrt(p) * 3.0
    rad = np.pi * 4.0 * np.sqrt(p)
    x = r * np.cos(rad)
    y = r * np.sin(rad)
    return x,y


p = np.linspace(0,1,100)
x,y = g(p)

plt.figure(figsize=(6, 6))
plt.scatter(x, y, c=[0.8, 0.5, 0.5],s=10)
plt.xlim([-3, 3])
plt.ylim([-3, 3])
plt.show()
=====================================================================================
X = {'a': 12,'b':'xx'}

print('axx {b}zz{a}'.format(**X))
=====================================================================================
# progress bar tqdm
from tqdm import tqdm,trange
from time import sleep
# ncols = bar의 폭 조절
with tqdm(total=200,ncols=70) as pbar:
    for i in range(10):
        sleep(0.1)
        if (i+1) % 2 == 0:
            tqdm.write("Done task %i" % (i+1))   # print와 동일
        pbar.set_description("Processing {}-{}".format(i,i*10))  # progress bar 앞부분에 출력
        pbar.update(20)  # 위에서 설정한 total = 200을 20씩 업데이트 한다. 그러면 10번 실행. loop 회수와 일치시키면 됨
=====================================================================================
# Multi Processing,    if __name__ == '__main__': <--- 이것이 있는 파일에서 실행해야 함.

=====================================================================================
import time
from tqdm import tqdm
from contextlib import closing
from multiprocessing import Pool
from concurrent.futures import ProcessPoolExecutor
from functools import partial
def isPrime2(n):
    if n==2 or n==3: return True
    if n%2==0 or n<2: return False
    for i in range(3,int(n**0.5)+1,2):   # only odd numbers
        if n%i==0:
            return False    

    return True
items = [23245457771477,23245457771477,23245457771477,23245457771477,12345,456789,23245457771477,23245457771477,23245457771477,23245457771477,23245457771477]
items = items + items + items + items + items + items + items + items + items
def test():
    results = []
    fn = partial(isPrime2)
    with closing(Pool(processes=None)) as pool:
        for out in tqdm(pool.imap_unordered(isPrime2, items), total=len(items), desc="Prime Check"):
            results.append(out)
    print(results)
def test2():
    # 단순히 serial하게 처리. cpu process 1개만 사용.
    for item in tqdm(items, total=len(items), desc="Prime Check"):
        isPrime2(item)

def test3():
    # CPU 집약적인 작업을 위해 ProcessPoolExecutor를 사용하는게 좋습니다. ThreadPoolExecutor는 네트워크 작업 또는 I / O에 더 적합합니다
    executor = ProcessPoolExecutor(max_workers=None)
    futures = []

    for item in items:
        fn = partial(isPrime2,item)
        futures.append(executor.submit(fn))
        
    n_frames = [future.result() for future in tqdm(futures)]
    n_frames = [n_frame for n_frame in n_frames if n_frame is not None]
    print(n_frames)
if __name__ == '__main__':
    s = time.time()
    test()
    print(time.time()-s," sec")

    s = time.time()
    test2()
    print(time.time()-s," sec")

    s = time.time()
    test3()
    print(time.time()-s," sec")
=====================================================================================
numpy.testing.assert_allclose
numpy.array_equal
=====================================================================================
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

# tensorflow warning 
import logging
logging.getLogger('tensorflow').disabled = True
=====================================================================================
def sigmoid(x):
    "Numerically-stable sigmoid function."
    if x >= 0:
        z = exp(-x)
        return 1 / (1 + z)
    else:
        z = exp(x)
        return z / (1 + z)
	
def sigmoid(x):
    pos_mask = (x >= 0)
    neg_mask = (x < 0)
    z = np.zeros_like(x,dtype=float)
    z[pos_mask] = np.exp(-x[pos_mask])
    z[neg_mask] = np.exp(x[neg_mask])
    top = np.ones_like(x,dtype=float)
    top[neg_mask] = z[neg_mask]
    return top / (1 + z)
	
=====================================================================================
########## example 1
# index 3,5,1이 주어져 있으면, index [2,3,4], [4,5,6], [0,1,2] 의 값이 1인 array 만들기   

i0 =np.array([3,5,1])

b = np.vstack([i0-1,i0,i0+1]).T   # or b = np.array(list(zip(i0-1,i0,i0+1)))
c = np.tile(np.arange(3),[3,1]).T

a = np.zeros((3,10))
a[c,b]=1



######### example 2
batch_size=3
#alignment0 = np.random.randn(batch_size,10)
alignment0 = np.array([[ 0.53147691,  4.71839748, -1.29035515, -0.98584769, -0.27640441,
         1.90273668, -1.45894385, -0.8311972 ,  0.14568322, -1.10923294],
       [-0.60512821, -0.41684329, -0.34283085, -0.7411493 ,  0.29670264,
         0.29437037, -1.65130632, -0.21103169, -0.79904658,  0.25820306],
       [-1.0253159 ,  0.39568011,  0.42450628, -0.16309257,  0.4185017 ,
        2.89342868,  3.35246116, -0.19832729, -1.55400021,  0.54946349]])


prev= np.array([7,0,2])

Y = np.zeros((batch_size,10))
Y[np.tile(np.arange(batch_size),[batch_size,1]).T, np.vstack([prev-1,prev,prev+1]).T ] = 1
alignment_new = alignment0*Y

=====================================================================================
# with
class controlled_execution:
    def __enter__(self):
        print("enter...")
        return np.arange(4).reshape(2,-1)
    def __exit__(self, type, value, traceback):
        print("exit...")
        


with controlled_execution() as xx:
    print(xx.shape)
=====================================================================================
def softmax(x):  
    x = x - np.max(x,axis=-1,keepdims=True) 
    return np.exp(x) / np.sum(np.exp(x),axis=-1,keepdims=True)
=====================================================================================
#deep copy
def f(params):
    X = params[:] # 얕은 복사
    X[0] += 1.0   # params의 값도 같이 바뀐다.
    X.pop(2)
    return X

def copy_test():
    a = np.array([[1,2],[3,4]]).astype(np.float16)
    b = np.zeros_like(a)
    c = np.zeros_like(a)
    
    b = a   # shallow copy
    
    deep_copy=False
    if deep_copy:
        c[...] = a  # deep copy(c가 미리 선언되어 있어야 한다.  c = np.zeros_like(a)  )  
    else: c = a[:]   # c =a 와 동일
    b[1] = [3.6,5.6]  # a 값이 바뀐다. c는 별개 
    c[1] = [3.9,5.9]  # a,b와는 별개
    
    print("a: ", a,'\nb: ',b,'\nc: ',c)


def copy_test2():
    a = np.array([1.1,2,3])
    b = np.array([10.0,20,30])
    c = np.array([100.0,200,300])
    A=[a,b,c]
    
    B = f(A)
    B[0] = np.array([1.1,2,3])*2.0  #A의 값도 같이 바뀐다.
    print('A:', A)
    print('B:', B)

copy_test()
print('='*10)
copy_test2()

=====================================================================================
import itertools
# merge, list 병합
x = [['Bromwell', 'High', 'is', 'a'],['comedy.', 'It']]
y = list(itertools.chain(*x))
=====================================================================================
import itertools
import nltk
x = ["This is a foobar-like sentence.","Good muffins cost $3.88\nin New York.  Please buy me\ntwo of them.\nThanks."]
y= [nltk.word_tokenize(sent) for sent in x]
w = list(itertools.chain(*y))
z = nltk.FreqDist(w)    # zz=collections.Counter(w) 같은 결과
vocab = z.most_common(5) # zz.most_common(5)
=====================================================================================
import re
from konlpy.tag import Okt
a1 = re.sub("[^가-힣ㄱ-ㅎㅏ-ㅣ\\s]", "", '아 123 더빙.. 진짜 짜증나네요 목소리')
a2 = re.sub("[^가-힣ㄱ-ㅎㅏ-ㅣ0-9\\s]", "", '아 01023 더빙.. 진짜 짜증나네요 목소리')
a4 = re.sub("[^A-Za-z\\s]","",'copyright 2000 dou &glas: n. honorof, jill mccullough & barbara somerville.') # alphabet만 남기기
a5 = re.sub("[^A-Za-z0-9\\s]","",'copyright 2000 dou &glas: n. honorof, jill mccullough & barbara somerville.')# alphabet, 숫자만 
print(a1)
print(a2)

okt=Okt()
a3 = okt.morphs(a1, stem=True)
print(a3)
=====================================================================================
#  numpy array --> pandas DataFrame
data = np.array([[2,3,4.5],[3,4,2]])
df = pd.DataFrame(data,columns=['A','AA','B'])  
print(df)

# numpy array를 DataFrame에 칼럼으로 추가
df=df.join(pd.DataFrame(data,columns=['C','CC','D']))
print(df)

# column 삭제
df.drop('CC', axis=1, inplace=True)
print(df)
=====================================================================================
window, ubuntu 모두에서 사용가능한 file path 표기법

- 현재 디렉토리를 뜻하는 . 표기할 것
- 역 슬래쉬 안되고, 슬래쉬(1개 또는 2개)
=====================================================================================
a = np.arange(10)
idx = a>5  # array([False, False, False, False, False, False,  True,  True,  True,True])
print(a[idx])  # [6 7 8 9]
print(np.where(a>5))  # (array([6, 7, 8, 9], dtype=int64),)

=====================================================================================
# 살아 있는 놈만 뽑기
gt = gt[np.nonzero(np.any(gt > 0, axis=1))]
=====================================================================================
1. 파일 이름으로 부터 로드:
a = importlib.import_module('cc.any')  <----cc\any.py
a.ff(2,3)


2. 함수이름(string)으로 부터 로드:
globals()['ff'](2,3)
=====================================================================================

=====================================================================================

=====================================================================================
