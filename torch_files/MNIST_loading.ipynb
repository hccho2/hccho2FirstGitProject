{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wp94JgB_FH-T"
   },
   "source": [
    "## sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19565,
     "status": "ok",
     "timestamp": 1606822631757,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "txpv2fErFE6I",
    "outputId": "6da6a57a-b615-4d83-b2d0-abcf7cb8c6ff"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "mnist = fetch_openml('mnist_784',version=1,data_home=r'./')  # 14M.\n",
    "\n",
    "print(mnist.keys())\n",
    "\n",
    "print(mnist['data'].shape, mnist['target'].shape)   # 'data', 'target'모두 정수 numpy array(dtype없음)\n",
    "print(mnist['data'].dtype, mnist['target'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1053,
     "status": "ok",
     "timestamp": 1606822516091,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "u2VpikHv9J-X",
    "outputId": "f9f52522-0678-4089-f2a0-aefa1cd87f59"
   },
   "outputs": [],
   "source": [
    "mnist['data'].dtype, mnist['target'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 667,
     "status": "ok",
     "timestamp": 1606822697044,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "nX3074yJ9iTZ"
   },
   "outputs": [],
   "source": [
    "X = (mnist['data']/255).astype(np.float32)\n",
    "Y = mnist['target'].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "executionInfo": {
     "elapsed": 2126,
     "status": "ok",
     "timestamp": 1606822979569,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "i6sII6ao9oQf",
    "outputId": "b8cabd2f-b6ad-4570-a466-2c6efba180e0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(12):\n",
    "    plt.subplot(3,4,i+1)\n",
    "    plt.imshow(X[i].reshape(28,28),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXhcwvt8HEGX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKNl2IIWHa5g"
   },
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 648,
     "status": "ok",
     "timestamp": 1606823318631,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "2cOioP31HUdc"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1180,
     "status": "ok",
     "timestamp": 1606823225494,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "_zXwI7dEHqAb",
    "outputId": "3d805f51-d024-418c-d022-9ba3e7dba315"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()  # numpy array \n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)  # (60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((tf.cast(x_train[...,tf.newaxis]/255, tf.float32), tf.cast(y_train,tf.int32)))\n",
    "dataset = dataset.shuffle(1000).batch(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "executionInfo": {
     "elapsed": 2441,
     "status": "ok",
     "timestamp": 1606823796419,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "-3AsAX4PH1iB",
    "outputId": "1cd861ee-b91a-4f1d-dfa3-3de8b38930ac"
   },
   "outputs": [],
   "source": [
    "it = iter(dataset)\n",
    "x,y = it.next()\n",
    "for i in range(12):\n",
    "    plt.subplot(3,4,i+1)\n",
    "    plt.imshow(x[i].numpy()[:,:,0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "executionInfo": {
     "elapsed": 2347,
     "status": "ok",
     "timestamp": 1606823812567,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "3hXZ1YETIQ2d",
    "outputId": "4bab5b14-9553-491a-cf37-b7263f842bad"
   },
   "outputs": [],
   "source": [
    "for x,y in dataset.take(1):\n",
    "    for i in range(12):\n",
    "        plt.subplot(3,4,i+1)\n",
    "        plt.imshow(x[i].numpy()[:,:,0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1606823805240,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "8ClXVO3DIn76"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNGWIAh8Kd6n"
   },
   "source": [
    "## pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 636,
     "status": "ok",
     "timestamp": 1606824129003,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "tyMQXlkwKgR8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 639,
     "status": "ok",
     "timestamp": 1606824214847,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "TB7OnsGqKxu2",
    "outputId": "1a8f5a4b-da8a-4b5b-deac-da358540d610"
   },
   "outputs": [],
   "source": [
    "# 다운 받은 data는 PIL.Image.Image(np.array로 변환해 보면 shape(28,28) uint8)이다. transform을 통해 tensor로 변환해야 하다.\n",
    "# (28,28)이기 때문에, reshape이 필요없다.\n",
    "\n",
    "download_root = r'D:\\hccho\\CommonDataset\\mnist'  #---> 아래에 MNIST- raw, processed 2개의 subdirectory가 생성된다. \n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()]) # channel dim이 생성(1,28,28)\n",
    "\n",
    "train_dataset = datasets.MNIST(download_root, transform=transform, train=True, download=True)   # transform을 넣어야 한다.\n",
    "test_dataset = datasets.MNIST(download_root, transform=transform, train=False, download=True)\n",
    "\n",
    "#train_dataset[0][0].show()  # PIL.Image.Image\n",
    "\n",
    "print(len(train_dataset),len(test_dataset))   # 60000(1,28,28), 10000\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=12,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "executionInfo": {
     "elapsed": 2090,
     "status": "ok",
     "timestamp": 1606824270143,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "8PUzIKyWK2NL",
    "outputId": "31d47419-581f-41ac-adbd-477648669883"
   },
   "outputs": [],
   "source": [
    "it = iter(train_loader)\n",
    "x,y = it.next()\n",
    "for i in range(12):\n",
    "    plt.subplot(3,4,i+1)\n",
    "    plt.imshow(x[i,0].numpy(),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 636,
     "status": "ok",
     "timestamp": 1606824230701,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "5yAWL-ppLDp5",
    "outputId": "802a8bc8-220d-4c4a-fb94-99ef3d46a51b"
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msYkz-01L-OC"
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결론을 말하면, FC layer만으로는 그림판으로 입력한 숫자를 판별하지 못하다.\n",
    "- CNN으로 모델을 구성하면 잘 판별한다\n",
    "- image를 만들때, (28,28)로 만들지 말고, (100,100)정도로 만들면 resize과정에서 mnist dataset과 유사해 진다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_root = r'D:\\hccho\\CommonDataset\\mnist'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root=download_root, \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)   # ---> Dataset\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root=download_root, \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_dataset))\n",
    "len(train_dataset), len(train_loader), len(test_dataset), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/playlist?list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4\n",
    "# https://github.com/python-engineer/pytorch-examples\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.dropout(x)\n",
    "        out = self.l1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out\n",
    "\n",
    "# http://www.ccom.ucsd.edu/~cdeotte/programs/MNIST.html\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.pooling = nn.AvgPool1d(4)\n",
    "        self.l1 = nn.Linear(196,100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(100, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.unsqueeze(x,1)\n",
    "        out = self.pooling(out)\n",
    "        out = torch.squeeze(out,1)\n",
    "        out = self.l1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.keep_prob = 0.5\n",
    "        # L1 ImgIn shape=(?, 28, 28, 1)\n",
    "        #    Conv     -> (?, 28, 28, 32)\n",
    "        #    Pool     -> (?, 14, 14, 32)\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        # L2 ImgIn shape=(?, 14, 14, 32)\n",
    "        #    Conv      ->(?, 14, 14, 64)\n",
    "        #    Pool      ->(?, 7, 7, 64)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        # L3 ImgIn shape=(?, 7, 7, 64)\n",
    "        #    Conv      ->(?, 7, 7, 128)\n",
    "        #    Pool      ->(?, 4, 4, 128)\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1))\n",
    "\n",
    "        # L4 FC 4x4x128 inputs -> 625 outputs\n",
    "        self.fc1 = torch.nn.Linear(4 * 4 * 128, 625, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            self.fc1,\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=1 - self.keep_prob))\n",
    "        # L5 Final FC 625 inputs -> 10 outputs\n",
    "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
    "        out = self.layer4(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "#model = NeuralNet2(input_size, hidden_size, num_classes).to(device)   # ===> 별 효과 없음.\n",
    "model = CNN().to(device)\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.train()\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # origin shape: [100, 1, 28, 28]\n",
    "        # resized: [100, 784]\n",
    "        \n",
    "        if type(model) is CNN:\n",
    "            images = images.to(device)\n",
    "        else:\n",
    "            images = images.reshape(-1, 28*28).to(device)\n",
    "        \n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        \n",
    "        if type(model) is CNN:\n",
    "            images = images.to(device)\n",
    "        else:\n",
    "            images = images.reshape(-1, 28*28).to(device)\n",
    "        \n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그림판으로 그린 숫자 판별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "digit_files = glob.glob('*.png')\n",
    "print(digit_files)\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                                transforms.Resize((28,28),interpolation=2),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,),(0.3081,))\n",
    "                                    ])\n",
    "\n",
    "class MyDataset(Dataset): \n",
    "    \"\"\" Diabetes dataset.\"\"\" \n",
    "    # Initialize your data, download, etc. \n",
    "    def __init__(self,digit_files,transform=None): \n",
    "        self.digit_files = digit_files\n",
    "        self.images = [Image.open(f) for f in digit_files]\n",
    "        self.nSamples = len(digit_files)\n",
    "        \n",
    "        if transform:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = transforms.ToTensor()\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.nSamples\n",
    "    def __getitem__(self, index): \n",
    "        return self.transform(self.images[index]), self.digit_files[index]\n",
    "\n",
    "\n",
    "my_test_dataset = MyDataset(digit_files,transform_test)\n",
    "my_test_dataloader = DataLoader(my_test_dataset, batch_size=1,shuffle=False)\n",
    "\n",
    "\n",
    "it = iter(my_test_dataloader)\n",
    "a,b = it.next()\n",
    "a.shape, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "n_image = len(digit_files)\n",
    "ncols = 4\n",
    "nrows = np.int(np.ceil(n_image/ncols))\n",
    "\n",
    "for i, (x,f) in enumerate(my_test_dataloader):\n",
    "    x = x.to(device)\n",
    "    _,pred = model(x).max(-1)\n",
    "    plt.subplot(nrows,ncols,i+1)\n",
    "    plt.imshow(x[0,0].to('cpu').numpy(),cmap='gray')\n",
    "    plt.title(pred[0].item())\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict a sigle image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,img):\n",
    "    model.eval()\n",
    "    \n",
    "    if type(model) is CNN:\n",
    "        img_tensor = transform_test(img).unsqueeze(0).to(device) # (1,28,28)\n",
    "    else:\n",
    "        img_tensor = transform_test(img).reshape(-1, 28*28).to(device) # (1,28,28)\n",
    "\n",
    "    _,pred = model(img_tensor).max(-1)\n",
    "    return pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'seven2.png'\n",
    "#path = 'eight.png'\n",
    "#path = 'seven.png'\n",
    "#path = 'three.png'\n",
    "#path = 'five.png'\n",
    "#path = 'my_digit4.png'\n",
    "path = 'my_digit2.png'\n",
    "#path = 'mnist_digit.png'\n",
    "# img = Image.open(path).convert('L').resize((28, 28))\n",
    "# img_tensor = transform(img).reshape(-1,28*28)\n",
    "\n",
    "\n",
    "img = Image.open(path)\n",
    "#img = Image.fromarray(drawing_image)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = transforms.Grayscale(num_output_channels=1)(img)\n",
    "tr = transforms.Resize((28,28))(tr)\n",
    "temp = np.array(tr).astype(np.uint8)  #, img_tensor.shape\n",
    "print(temp.dtype)\n",
    "np.savetxt('mnist_digit.txt',temp,fmt='%i')\n",
    "im = Image.fromarray(temp)\n",
    "im.save(\"resized_mnist_fig.png\")\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = transform_test(img).reshape(-1,28*28).to(device)\n",
    "a = transform_test(img).unsqueeze(0).to(device) # (1,28,28)\n",
    "model(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import ctypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a 600 x 600 pixels canvas for mouse drawing\n",
    "canvas = np.ones((600,600), dtype=\"uint8\") * 255\n",
    "# designating a 400 x 400 pixels point of interest on which digits will be drawn\n",
    "canvas[100:500,100:500] = 0\n",
    "\n",
    "start_point = None\n",
    "end_point = None\n",
    "is_drawing = False\n",
    "\n",
    "def draw_line(img,start_at,end_at):\n",
    "    cv2.line(img,start_at,end_at,255,15)\n",
    "\n",
    "def on_mouse_events(event,x,y,flags,params):\n",
    "    global start_point\n",
    "    global end_point\n",
    "    global canvas\n",
    "    global is_drawing\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        if is_drawing == False:\n",
    "            is_drawing=True\n",
    "            start_point = (x,y)\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if is_drawing:\n",
    "            end_point = (x,y)\n",
    "            draw_line(canvas,start_point,end_point)\n",
    "            start_point = end_point\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        is_drawing = False\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"Test Canvas\")\n",
    "cv2.setMouseCallback(\"Test Canvas\", on_mouse_events)\n",
    "\n",
    "\n",
    "while(True):\n",
    "    cv2.imshow(\"Test Canvas\", canvas)\n",
    "    key = cv2.waitKey(1) & 0xFF \n",
    "    if key == ord('c'):\n",
    "        canvas[100:500,100:500] = 0\n",
    "    elif key == ord('d'):\n",
    "        drawing_image = canvas[100:500,100:500]\n",
    "        break\n",
    "        #result = net.predict(image)\n",
    "        #print(\"PREDICTION : \",result)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "plt.imshow(drawing_image,cmap='gray')\n",
    "\n",
    "draw_image=Image.fromarray(drawing_image)\n",
    "pred = predict(model,draw_image).item()\n",
    "\n",
    "ctypes.windll.user32.MessageBoxW(0, str(pred), \"Prediction\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing2: 이미지를 입력받아 파일로 저장(clear후 반복 저장 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageTk, Image, ImageDraw\n",
    "import PIL\n",
    "from tkinter import *\n",
    "import os\n",
    "width = 200\n",
    "height = 200\n",
    "center = height//2\n",
    "white = (255, 255, 255)\n",
    "black = (0,0,0)\n",
    "green = (0,128,0)\n",
    "\n",
    "def save():\n",
    "    j=0\n",
    "    filename = \"image\" + str(j) + \".png\"\n",
    "    \n",
    "    while os.path.exists(filename):\n",
    "        j += 1\n",
    "        filename = \"image\" + str(j) + \".png\"\n",
    "    image1.save(filename)\n",
    "\n",
    "def clear():\n",
    "    cv.delete(\"all\")\n",
    "    global image1, draw\n",
    "    image1 = PIL.Image.new(\"RGB\", (width, height), black)  # 저장되는 backgroudn color\n",
    "    draw = ImageDraw.Draw(image1)\n",
    "    \n",
    "    \n",
    "\n",
    "def paint(event):\n",
    "    x1, y1 = (event.x - 1), (event.y - 1)\n",
    "    x2, y2 = (event.x + 1), (event.y + 1)\n",
    "    cv.create_oval(x1, y1, x2, y2, fill=\"white\",width=20)  # 저장되는 color\n",
    "    draw.line([x1, y1, x2, y2],fill=\"white\",width=20)\n",
    "\n",
    "root = Tk()\n",
    "\n",
    "# Tkinter create a canvas to draw on\n",
    "cv = Canvas(root, width=width, height=height, bg='white')\n",
    "cv.pack()\n",
    "\n",
    "\n",
    "image1 = PIL.Image.new(\"RGB\", (width, height), black)  # 저장되는 backgroudn color\n",
    "draw = ImageDraw.Draw(image1)\n",
    "\n",
    "\n",
    "\n",
    "cv.pack(expand=YES, fill=BOTH)\n",
    "cv.bind(\"<B1-Motion>\", paint)\n",
    "\n",
    "button1=Button(text=\"save\",command=save, width=10, height=2)\n",
    "button2=Button(text=\"clear\",command=clear, width=10, height=2)\n",
    "button1.pack(side='left',anchor='s')  # left --> south ---> 왼쪽 아래\n",
    "button2.pack(side='right',anchor='s') # 오른쪽 아래.\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMiwbDulbLWIZVOkveQbovi",
   "collapsed_sections": [],
   "name": "MNIST_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
