{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wp94JgB_FH-T"
   },
   "source": [
    "## sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19565,
     "status": "ok",
     "timestamp": 1606822631757,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "txpv2fErFE6I",
    "outputId": "6da6a57a-b615-4d83-b2d0-abcf7cb8c6ff"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "mnist = fetch_openml('mnist_784',version=1,data_home=r'./')  # 14M.\n",
    "\n",
    "print(mnist.keys())\n",
    "\n",
    "print(mnist['data'].shape, mnist['target'].shape)   # 'data', 'target'모두 정수 numpy array(dtype없음)\n",
    "print(mnist['data'].dtype, mnist['target'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1053,
     "status": "ok",
     "timestamp": 1606822516091,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "u2VpikHv9J-X",
    "outputId": "f9f52522-0678-4089-f2a0-aefa1cd87f59"
   },
   "outputs": [],
   "source": [
    "mnist['data'].dtype, mnist['target'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 667,
     "status": "ok",
     "timestamp": 1606822697044,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "nX3074yJ9iTZ"
   },
   "outputs": [],
   "source": [
    "X = (mnist['data']/255).astype(np.float32)\n",
    "Y = mnist['target'].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "executionInfo": {
     "elapsed": 2126,
     "status": "ok",
     "timestamp": 1606822979569,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "i6sII6ao9oQf",
    "outputId": "b8cabd2f-b6ad-4570-a466-2c6efba180e0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(12):\n",
    "    plt.subplot(3,4,i+1)\n",
    "    plt.imshow(X[i].reshape(28,28),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXhcwvt8HEGX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKNl2IIWHa5g"
   },
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 648,
     "status": "ok",
     "timestamp": 1606823318631,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "2cOioP31HUdc"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1180,
     "status": "ok",
     "timestamp": 1606823225494,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "_zXwI7dEHqAb",
    "outputId": "3d805f51-d024-418c-d022-9ba3e7dba315"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()  # numpy array \n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)  # (60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((tf.cast(x_train[...,tf.newaxis]/255, tf.float32), tf.cast(y_train,tf.int32)))\n",
    "dataset = dataset.shuffle(1000).batch(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "executionInfo": {
     "elapsed": 2441,
     "status": "ok",
     "timestamp": 1606823796419,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "-3AsAX4PH1iB",
    "outputId": "1cd861ee-b91a-4f1d-dfa3-3de8b38930ac"
   },
   "outputs": [],
   "source": [
    "it = iter(dataset)\n",
    "x,y = it.next()\n",
    "for i in range(12):\n",
    "    plt.subplot(3,4,i+1)\n",
    "    plt.imshow(x[i].numpy()[:,:,0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "executionInfo": {
     "elapsed": 2347,
     "status": "ok",
     "timestamp": 1606823812567,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "3hXZ1YETIQ2d",
    "outputId": "4bab5b14-9553-491a-cf37-b7263f842bad"
   },
   "outputs": [],
   "source": [
    "for x,y in dataset.take(1):\n",
    "    for i in range(12):\n",
    "        plt.subplot(3,4,i+1)\n",
    "        plt.imshow(x[i].numpy()[:,:,0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1606823805240,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "8ClXVO3DIn76"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNGWIAh8Kd6n"
   },
   "source": [
    "## pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 636,
     "status": "ok",
     "timestamp": 1606824129003,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "tyMQXlkwKgR8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 639,
     "status": "ok",
     "timestamp": 1606824214847,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "TB7OnsGqKxu2",
    "outputId": "1a8f5a4b-da8a-4b5b-deac-da358540d610"
   },
   "outputs": [],
   "source": [
    "# 다운 받은 data는 PIL.Image.Image(np.array로 변환해 보면 shape(28,28) uint8)이다. transform을 통해 tensor로 변환해야 하다.\n",
    "# (28,28)이기 때문에, reshape이 필요없다.\n",
    "\n",
    "download_root = r'D:\\hccho\\CommonDataset\\mnist'  #---> 아래에 MNIST- raw, processed 2개의 subdirectory가 생성된다. \n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()]) # channel dim이 생성(1,28,28)\n",
    "\n",
    "train_dataset = datasets.MNIST(download_root, transform=transform, train=True, download=True)   # transform을 넣어야 한다.\n",
    "test_dataset = datasets.MNIST(download_root, transform=transform, train=False, download=True)\n",
    "\n",
    "#train_dataset[0][0].show()  # PIL.Image.Image\n",
    "\n",
    "print(len(train_dataset),len(test_dataset))   # 60000(1,28,28), 10000\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=12,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "executionInfo": {
     "elapsed": 2090,
     "status": "ok",
     "timestamp": 1606824270143,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "8PUzIKyWK2NL",
    "outputId": "31d47419-581f-41ac-adbd-477648669883"
   },
   "outputs": [],
   "source": [
    "it = iter(train_loader)\n",
    "x,y = it.next()\n",
    "for i in range(12):\n",
    "    plt.subplot(3,4,i+1)\n",
    "    plt.imshow(x[i,0].numpy(),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 636,
     "status": "ok",
     "timestamp": 1606824230701,
     "user": {
      "displayName": "Heecheol Cho",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjX329YmmK5EOCLjZGYupvhhyKPjyr-kS3DftPICg=s64",
      "userId": "11416361730564561965"
     },
     "user_tz": -540
    },
    "id": "5yAWL-ppLDp5",
    "outputId": "802a8bc8-220d-4c4a-fb94-99ef3d46a51b"
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msYkz-01L-OC"
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결론을 말하면, FC layer만으로는 그림판으로 입력한 숫자를 판별하지 못하다.\n",
    "- CNN으로 모델을 구성하면 잘 판별한다\n",
    "- image를 만들때, (28,28)로 만들지 말고, (100,100)정도로 만들면 resize과정에서 mnist dataset과 유사해 진다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_root = r'D:\\hccho\\CommonDataset\\mnist'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root=download_root, \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)   # ---> Dataset\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root=download_root, \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchvision.datasets.mnist.MNIST\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 600, 10000, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(train_dataset))\n",
    "len(train_dataset), len(train_loader), len(test_dataset), len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/playlist?list=PLqnslRFeH2UrcDBWF5mfPGpqQDSta6VK4\n",
    "# https://github.com/python-engineer/pytorch-examples\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.dropout(x)\n",
    "        out = self.l1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out\n",
    "\n",
    "# http://www.ccom.ucsd.edu/~cdeotte/programs/MNIST.html\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.pooling = nn.AvgPool1d(4)\n",
    "        self.l1 = nn.Linear(196,100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(100, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.unsqueeze(x,1)\n",
    "        out = self.pooling(out)\n",
    "        out = torch.squeeze(out,1)\n",
    "        out = self.l1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.keep_prob = 0.5\n",
    "        # L1 ImgIn shape=(?, 28, 28, 1)\n",
    "        #    Conv     -> (?, 28, 28, 32)\n",
    "        #    Pool     -> (?, 14, 14, 32)\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        # L2 ImgIn shape=(?, 14, 14, 32)\n",
    "        #    Conv      ->(?, 14, 14, 64)\n",
    "        #    Pool      ->(?, 7, 7, 64)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        # L3 ImgIn shape=(?, 7, 7, 64)\n",
    "        #    Conv      ->(?, 7, 7, 128)\n",
    "        #    Pool      ->(?, 4, 4, 128)\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1))\n",
    "\n",
    "        # L4 FC 4x4x128 inputs -> 625 outputs\n",
    "        self.fc1 = torch.nn.Linear(4 * 4 * 128, 625, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            self.fc1,\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=1 - self.keep_prob))\n",
    "        # L5 Final FC 625 inputs -> 10 outputs\n",
    "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
    "        out = self.layer4(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "#model = NeuralNet2(input_size, hidden_size, num_classes).to(device)   # ===> 별 효과 없음.\n",
    "model = CNN().to(device)\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.2003\n",
      "Epoch [1/5], Step [200/600], Loss: 0.0891\n",
      "Epoch [1/5], Step [300/600], Loss: 0.0809\n",
      "Epoch [1/5], Step [400/600], Loss: 0.0343\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0411\n",
      "Epoch [1/5], Step [600/600], Loss: 0.1078\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0303\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0137\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0642\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0497\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0070\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0155\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0094\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0292\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0078\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0463\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0037\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0118\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0310\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0383\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0258\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0610\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0705\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0037\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0235\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0295\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0391\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0372\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0789\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0123\n",
      "model saved:  mnist_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.train()\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # origin shape: [100, 1, 28, 28]\n",
    "        # resized: [100, 784]\n",
    "        \n",
    "        if type(model) is CNN:\n",
    "            images = images.to(device)\n",
    "        else:\n",
    "            images = images.reshape(-1, 28*28).to(device)\n",
    "        \n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "torch.save(model.state_dict(), 'mnist_model.pth')\n",
    "print('model saved: ','mnist_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 99.17 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        \n",
    "        if type(model) is CNN:\n",
    "            images = images.to(device)\n",
    "        else:\n",
    "            images = images.reshape(-1, 28*28).to(device)\n",
    "        \n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그림판으로 그린 숫자 판별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mnist_images\\\\eight.png', 'mnist_images\\\\image0.png', 'mnist_images\\\\image1.png', 'mnist_images\\\\image2.png', 'mnist_images\\\\mnist_digit.png', 'mnist_images\\\\my_digit2.png', 'mnist_images\\\\my_digit4.png', 'mnist_images\\\\my_digit5.png', 'mnist_images\\\\my_digit9.png', 'mnist_images\\\\resized_fig.png', 'mnist_images\\\\resized_mydigit_fig.png', 'mnist_images\\\\seven.png', 'mnist_images\\\\three.png']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 28, 28]), ('mnist_images\\\\eight.png',))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "digit_files = glob.glob('mnist_images/*.png')   ################################## ------> check didit image directory\n",
    "print(digit_files)\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                                transforms.Resize((28,28),interpolation=2),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,),(0.3081,))\n",
    "                                    ])\n",
    "\n",
    "class MyDataset(Dataset): \n",
    "    \"\"\" Diabetes dataset.\"\"\" \n",
    "    # Initialize your data, download, etc. \n",
    "    def __init__(self,digit_files,transform=None): \n",
    "        self.digit_files = digit_files\n",
    "        self.images = [Image.open(f) for f in digit_files]\n",
    "        self.nSamples = len(digit_files)\n",
    "        \n",
    "        if transform:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = transforms.ToTensor()\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.nSamples\n",
    "    def __getitem__(self, index): \n",
    "        return self.transform(self.images[index]), self.digit_files[index]\n",
    "\n",
    "\n",
    "my_test_dataset = MyDataset(digit_files,transform_test)\n",
    "my_test_dataloader = DataLoader(my_test_dataset, batch_size=1,shuffle=False)\n",
    "\n",
    "\n",
    "it = iter(my_test_dataloader)\n",
    "a,b = it.next()\n",
    "a.shape, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEYCAYAAABIoN1PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXjU5bn4//c9SyaTjSxEshAIYBqQsJWCqKhU2epSXL5aEbWtttie47nOUdvzpT39Xcd+W/ujXnra/tqqRyq1aqu41Z6vUnABka2YsAsYDARIwpKEhOzbzDy/P2aShhIlZLZPJvfruuaCmSSfz52589zzzDPP53nEGINSSqnYYYt2AEoppUJLC7tSSsUYLexKKRVjtLArpVSM0cKulFIxRgu7UkrFGC3sSikVYyxb2EUkX0RWi0i9iJwUkd+IiCPacQ11ItL8DzeviPw62nGpv9O2Y10i8oCIlIhIh4g8F67zWLawA08C1UA2MBW4GvinqEakMMYkdd+AEUAb8GqUw1Jn07ZjXceBnwIrw3kSKxf2McArxph2Y8xJYA0wMcoxqbP9L/wFZGO0A1Fn0bZjUcaYN4wxbwKnw3keKxf2XwF3iEiCiOQCX8H/B6qs4+vA80bXpbAabTtDnJUL+wb8vYxGoBIoAd6MakSqh4iMwv8W/w/RjkWdQ9vOEGfJwi4iNmAt8AaQCAwH0oCfRzMudZZ7gE3GmPJoB6L+TtuOAosWdiAdyAN+Y4zpMMacBn4PXBfdsFQv96C9dSvStqOsWdiNMbVAOfBdEXGISCr+8dzd0Y1MAYjI5UAuOhvGcrTtWFsgJ/GAHbCLSHw4pqJasrAH3AIsBGqAMsADPBjViFS3rwNvGGOaoh2I6pO2Hev6Ef4pwsuAuwL//1GoTyI6oUEppWKLlXvsSimlBkALu1JKxZigCruILBSRUhEpE5FloQpKhYbmx7o0N9Y22PMz4DF2EbEDB4F5+C+CKAYWG2P2hy48NVCaH+vS3FhbLOQnmGk2M4EyY8xhABF5GVgEfOYvLyIR+aTWGCOROI/FaX6sy7K5AWqNMZkROpdVWTY//W07wQzF5AIVve5XBh47i4gsDSxTWTKQk9jtdhwOBw6HA7vdjshQrwn9Fvb8iAg2mw2bTT+quUARaTsDdDSC57IqK+enX4LpsfdVYc951TLGPAM8Axf2qma320lLS2P69OkkJycD0NLSwq5duzhx4sQAQx5SQpoft9tNeno6drsdr9eL0+kkKSmJlJQUfD4fe/fupaWlJXTRx7aQ5sZms2G323teYL1eLx6PJ0ShDklhrW2REExhr8R/6XK3kfjXGg6KzWYjIyODwsJClixZwuzZszlz5gxOp5PExERWrFjBb3/7W7xeb7CninUhy8+wYcO44YYb+NrXvkZaWhpnzpwBIC8vjxEjRnDq1CmWLFnCvn37go96aAhZbhITEyksLGTMmDG43W7sdjtHjx5l06ZNWtwHLiy1rZuI4HK5aG9vD9UhzxFMYS8GCkRkDFAF3AHcGUwwdrudSZMmcccdd3DllVciIjz33HOsXbuW4cOHs2zZMjIyMnQ4pn9Ckh+Hw8HVV1/Nd77zHdLT02lsbKSxsZGuri4SEhIoKCigpaUFvdDtgoQkN6mpqcydO5evf/3rTJo0iYSEBNxuN9u2beP222+nrq4u1HEPFSGvbd1EhLFjx1JUVMTbb78dthffARd2Y4xHRB7Av5KcHVhpjAmqy5aXl8eDDz5IQUEB77//PmvWrGHXrl20trYybdo03G43dXV1WkT6IVT5SUlJYfbs2XR1dfGzn/2MAwcOcOLECYwxjBo1ij/96U8cPHiQU6dOhfx3iFWhyE1KSgpf+cpXmDt3LkeOHOGTTz4hLy+P6667jpEjR5KQkKCFfYDCUdu6ZWVl8f3vf5+MjAzWrFljvcIOYIxZDawOUSwUFRUxceJEnn76aV599VUaGhoAcLlcXHHFFYgI27Zt02GYfgpFfnJychg/fjyffvopH3zwAVVVVT1fGz58OHFxcXz00UfU19cHG+6QEkxu7HY7kydP5pvf/CZ79+7lV7/6FXV1dUydOpUZM2bg9Xq18xOkUNe2bmPHjuXmm29m69atYc2RpaYzJCQk0NHRwc6dO2lsbOx5PDs7m3nz5lFcXMzHH38cxQiHFofDwcUXX8yYMWOor68/Z0xw0qRJ+Hw+NmzYgM/ni1KUQ4/dbicvL48JEybgdrvxeDw0NzdTW1tLa2ur5sLC7HY7Ho+H1tbWsJ7HUoW9oaEBt9vNJZdcgsPhfzNht9uZN28eWVlZ/PnPf6a5uTnKUQ4ddrudiy66CIfDwZEjR876Y4yLi+Pqq6+mrKyM3bt1RdhIEhHi4uKIj49n5syZzJ8/n4yMDIwx+Hw+XC5XT/tR1tLR0UFbWxtAWHvslsr+/v37OXbsGPfccw8fffQRpaWlTJs2jXvvvZfNmzezc+fOaIc4pDidTlwuFzt37qSkpOSsHntGRgYzZszg/fff75kloyLD5/NRXV3Np59+SnJyMtdffz3Dhw+nsrISt9tNYmIiiYmJ0Q5T9cHhcNDa2srBgwfD+s7KUj32qqoqnn76adLT01m2bBlFRUUsW7YMu93OCy+8oPOkIywuLo5jx47x3//93+zdu/esHsbo0aPJzs6mrKxM3/pHWFdXF5s2beKRRx7h/fffJykpiRtuuIH/+I//IC8vj+TkZCZMmKCzxyyovr6e/fv3k5ycHNYL+yzVY/f5fKxbt47HH3+c5cuXM2XKFHJzc3nooYf07X4UnDlzhrVr1+LxeM759P6yyy4DoKlJ99qIhqamJtavX09ZWRk33ngj9957L4WFhTidThwOB2lpafoBqgU5HA4KCgpwOp1hfeG1VGEH6Ozs5M033yQzM5Of/vSntLS0UFFRob3CKPD5fJ95EUVXVxcOh0M/84iirq4uDh8+zMqVKykrK2POnDncdttt5Oaec/W7soiEhASSkpIoLy8Pa4/dUkMx3UaPHk1WVhYiQmZmJo8++iiTJ0+OdlgqwGazUVhYiIjo8g4W0NTUxNtvv80jjzxCSUkJHo+n5wM6ZS1tbW2UlJQwceJEMjPDt9aaJQv7rFmzuO+++0hKSuLDDz8kISGBhx9+mIyMjGiHpvCvGzNy5EhOnDhBRUXF+X9ARURHRwfV1dW0tLTo51EWVV9fT25uLlOmTCElJSVs57FkYV+9ejWrVq2ira2NVatW8dRTT3HZZZcxZ86caIemgMzMTAoLC6murtYxdgsxxtDc3ExLSwtOpzPa4ajPkJWVRXx8fFjH2C1Z2FNSUpgyZQrbt2/nvffeY/369Rw/fpy5c+fidrujHd6QN3z4cFJTU6mrq6Orqyva4ahePB4PaWlpuFyuaIei+uBwOCLyomu5wu50Orn11lvJzc3l5z//OeXl5Rw/fpwPPviA8ePHM2LEiGiHOORlZGQQHx9PaWmpFnYLERGSk5OJi4vrWepaWYvP58MYg9PpJDU1NWznsVxhT09PZ8GCBWzdupWNGzfi8/no6upi3759JCQkkJWVFe0Qh7z8/HycTicnT56MdiiqF5vNhtvt7rkyVVlP9wfbDocjrB+eWm66o9vtJi0tjVWrVvWM3/p8vp7VA7XHHl0Oh4NLLrkE4KwFwVT0da/z3dbWRm1tbbTDUX1oaGjgk08+Yc+ePezduzds5zlvj11E8kRkvYgcEJF9IvKvgccfEZEqEdkVuF0XysDGjBlDTk4OLpeLuLg4EhISsNlsunnAP4h0ftxuN6NGjeq5vkB9tmi0naamJv70pz+xefPmUB0yZkUjPy0tLTz55JP85Cc/4dChQ6E67Dn602P3AA8bY3aISDKwXUTeDXztF8aYx0MZUENDA8XFxdx4440UFBRQVlaG1+tl4sSJNDc3h/XJGKQimp+kpCSGDx/OkSNHdA77+UU0N11dXfzxj3+kqqqKo0d169J+iGh+wD/6sHHjxrAvrXzewm6MOQGcCPy/SUQO0MfGrqHS0NDA8uXLmTt3LtOmTSM/Px9jDPX19bz00kuUl5eH69SDUqTzM2zYMGpqanjppZeoqakJ12liQqRz4/P5evYr0OUEzi/S+ekWiVEHuZA/ABHJBz4EioCHgG8AjUAJ/le+z91tob8bvnaPFbrd7p7lR30+Hy0tLf3aJ9AYMyRXP4pEfrKzs8nLy+Pjjz8e8JrSQzE/kWo7IbDdGPOlCJ3LMgZLfvrddowx/boBScB24JbA/RH4t42yAY/i3z6qr59biv/JKcG/03fYb/39nWLpFqn8iIix2WyaHwvmJkS3kmg/X5qf4NtOv3rsIuIE3gLWGmP+q4+v5wNvGWOKznMca72qxQjNj3UNttwwxHrsgy0//W075x1jF/91r88CB3r/4iKSbfxjVAA3A/3Zs64ZKO1PYAMwHKgFRofp+Jak+bGuEOemFmgJ/Btq3bkBzU9MtJ3z9thFZDawEdgLdK+d+0NgMTAV/1uEI8D9vZ6MzzpWSbh6A+E8tpVpfqwrlLkJHC8sz+FQzA3Edtvpz6yYTUBf3f+Q7+CtLpzmx7o0N9YWy/mx3JICSimlghPpwv7MID32UKH5sbZwPYeam+BZqu1c0Dx2pZRS1qdDMUopFWO0sCulVIyJWGEXkYUiUioiZSKyLMhjRWXFyVilubE2zY91WTU3ERljFxE7cBCYB1QCxcBiY8z+AR4vG8g2vVZlA24CbgeaTRhWZYtVmhtr0/xYl5VzE6ke+0ygzBhz2BjTCbwMLBrowYwxJ4wxOwL/bwIisipbjNLcWJvmx7osm5tIFfZcoPeuDJWE6I8psJbDNGBb4KEHRGSPiKwUkbRQnCPGaW6sTfNjXZbNTaQKe19XdwU9BiQiScDrwL8ZYxqBp4Bx+C8HPgE8Eew5hgDNjbVpfqzLsrmJVGGvBPJ63R8JHA/mgIFV2V4H/miMeQPAGHPKGOM1xviAFfjfKqnPp7mxNs2PdVk2N5Eq7MVAgYiMEZE44A7gfwZ6sM9bla3Xt/V3VbahTnNjbZof67Jsbvqz52nQjDEeEXkAWIt/AfuVxph9QRzyCuBuYK+I7Ao89kNgsYictSpbEOcYEjQ31qb5sS4r50aXFFBKqRijV54qpVSM0cKulFIxRgu7UkrFGC3sSikVY7SwK6VUjNHCrpRSMUYLu1JKxRgt7EopFWO0sCulVIzRwq6UUjFGC7tSSsUYLexKKRVjtLArpVSMsWxhF5EJIrJORBoCO4DfHO2YFIiIS0SeFZGjItIkIjtF5CvRjkudS0QKRKRdRF6MdizKT0Q+COSkOXArDcd5LFnYRcQB/AV4C0gHlgIvisgXohqYAv8a/hXA1cAw4P8BXgns0ais5bf4N4NQ1vKAMSYpcCsMxwksWdiB8UAO8IvAllDrgM34F6FXUWSMaTHGPGKMOWKM8Rlj3gLKgenRjk39nYjcAZwB3o92LCryrFrY+9okVoCiSAeiPp+IjAC+AASzc4wKIRFJAf4P8HC0Y1F9+n9FpFZENovInHCcwKqF/ROgGvi+iDhFZD7+t/4J0Q1L9RbYePePwB+MMZ9EOx7V4yfAs8aYimgHos7xv4GxQC7wDPB/RWRcqE9iycJujOkCbgKuB07i73m8gn9XcGUBImIDXgA6gQeiHI4KCOyNORf4RbRjUecyxmwzxjQZYzqMMX/AP8R8XajPE5HNrAfCGLMHfy8dABHZAvwhehGpbr12Ux8BXBd4IVbWMAfIB47500QSYBeRS4wxX4xiXKpvhr6HnoNi2c2sRWQycBD/u4p/Av4ZGG+M6YhqYAoReRqYCsw1xjRHOx71dyKSAKT0euh7+Av9d40xNVEJSgEgIqnApcAGwAN8Df9wzBeNMSGd9mjZHjv+GTDfApzARmCeFvXoE5HRwP1AB3Ay0CsEuN8Y88eoBaYAMMa0Aq3d90WkGWjXom4JTuCn+Gf9efF/lnhTqIs6WLjHrpRSamAs+eGpUkqpgQuqsIvIQhEpDVzyvyxUQanQ0PxYl+bG2gZ7fgY8FCMidvwfbs7DPw2xGFhsjNkfuvDUQGl+rEtzY22xkJ9geuwzgTJjzGFjTCfwMrAoNGGpEND8WJfmxtoGfX6CmRWTi38xqG6V+KfynEVEluJfxAsitJ6IMSbk80IHIc2PdVk2N0CtMSYzQueyKsvmp79tJ5jC3tcJzhnXMcY8g3+uJiKiU3AiJyz5ERHsdjsOhwOn04nD4aCrq4vW1lZ8Pl/wUQ8NYW87IoLb7cZms11obo5eyHliVEjzY7fbycjIICEhAZut70ESm81GamoqNpuNI0eOUFNTQzAzFoMp7JVAXq/7I4HjQRxPhVZI8yMiJCQkkJuby9ixY8nLyyMvL4+srCwqKip4/fXXOXDgQFB/jENI2NtObm4ut912Gy6XixdeeIGqqqpQHj7WhTQ/BQUFPPjgg0yZMgW73d7n99jtdlJTU2lra+PJJ5/kueeeo6WlZaCnDKqwFwMFIjIGqALuAO4M4nhnsdls2Gw2ui+A8fl8+Hw+LRz9F7L8xMfHM27cOK688kpuvPFGJk+eTEpKSk/vw2azMXLkSP793/+dhoaGkP0CMSysbcftdvPtb3+bhx56iOPHj7Nx40Yt7BcmZPmx2WzMnDmTBQsWkJKSwqlTp/B4PH1+b319PZWVldTV1QX97nfAhd0Y4xGRB4C1gB1YaYwJeulWh8NBcnIyOTk5jBo1CpfLhdfrpb6+nkOHDlFdXY3X6w32NDEvVPlxOp3MmjWL+++/nzlz5uByuTh69Chbtmyhuroat9vN1772NWbNmkV2drYW9n4IV9sBiIuLY+HChdx5p78Ovfbaa5SWhmWTnpgVyvzEx8czduxYUlJS2LBhA88//zytra19fm9bWxvHjx/n5MmTtLW1DfwXIMglBYwxq4HVQUXQS0JCAhdffDFXXXUVM2fOpKioCLfbjcfjoaqqir/+9a+8/vrrVFVVac+9H0KRn/j4eC677DJmz55NeXk569evZ8OGDRw8eJCGhgbGjRvHddddR2JiIklJSSGKPPaFuu2Af7hs2rRpfP/73ycvL481a9awYsUKamtrQ3maISFU+XG73WRlZeFwONi6dSvvvPNOUEMs/WWJtWJEhOTkZC677DJuvfVWrrrqKtLS0gBob2/HZrORk5NDfHw8hw4dora2lvb29ihHPTR0dHSwdetWurq62LVrF7t27TrrrWJra6u+g7KIYcOGcc899zB16lSKi4t57LHHOHbsWLTDGtKSk5PJyMigs7OTiooKuroisxBq1Au7iJCamsqcOXO49957mTlzJp2dnXz44Yfs2rWLw4cPk5WVxe23386xY8dobm7W3noEdXZ2snXrVnbs2EFbW9s5f5ijR48mKSmJ1tbWzxw7VJFx6aWXMn/+fNrb23n66af56KOPAMjJySEuLo6Kigp9EY6wpKQkUlJSaGtro7a2NmIzx6Je2JOTk7n22mtZunQpX/rSlygvL+fNN99k7dq1HDlyBBHhlltuwePx8Omnn7Jv3z46OzujHfaQ0tHRQUfHuQtrxsfHs2jRIhISEjhw4IB+QBdFWVlZ3HbbbeTk5LB69WrWrl2Lx+Phoosu4sc//jEJCQn8+Mc/5uDBg9EOdUjJyMggPT2d+vp66uvrI/bCGtXCbrfb+cIXvsBtt93GjBkzOHXqFC+++CKvvPIKNTU1JCYmsnDhQu666y7GjRvHtm3b6Ojo0B67RUyePJnrr7+e5uZmXn/9dU6fPh3tkIaklJQUli5dyg033EBTUxMvvvgidXV1iAgXX3wxCxcu5PTp06SmpkY71CFFREhKSiI+Pp66urqIjjZEtbCnp6dz7bXXcumll+Lz+VizZg1r166lqamJkSNHcuedd3LLLbcwYcIE2tra8Hq9WtQtIj4+niVLlpCVlcWGDRt455139AKlKLDZbFx++eXcfPPNxMXFsXz5ctatW4fP58Nms1FUVER6ejr79u3Td1QRZrfbGT58OCkpKdTV1TF8+HBGjx7N8OHDyc7OpqCggNraWlavXh3yTlFUC3tiYiJjx45l2LBhlJeXU1ZWxrhx41iwYAFXX301s2bNYvjw4YgI5eXl/O1vf9NhGIv48pe/zJ133kl7ezurVq2iuro62iENSePHj2fp0qWMHz+ev/zlL7zwwgs0NTUB/vHdRYsW4fP52Llzp+YowrovOnK73UybNo3f//73+Hw+UlNTSUhIID4+ntbWVlauXMl//ud/0tjYGLJzR7WwG2Po6OjA4/EwcuRI7rvvPpKSkkhNTSU5ORmXywX4Z15s3769ZyhGRVdKSgp33XUX6enp/OUvf+G1117Td1JREBcXxxVXXMGMGTPYv38/Tz75JDU1f98oaerUqcyYMYPa2lrWrl0bsRkZys/hcJCQkNDzb05ODl6vl7a2NqqqqhAR8vPzueGGG3jppZd6PuwOyblDdqQBOH36NG+//TadnZ0UFhaSmppKZWUltbW1JCUlcc0115CWlsbp06dZt24d9fX10QxXAS6XiyVLlrBw4ULq6+v5/e9/r3mJkqysLGbNmsWwYcN44YUX+Pjjj3tmJtntdhYuXMiwYcPYtGkTe/bsQUSIi4sjKSmJtra2z7xQRoWGz+ejpqaGffv2UVpaynvvvUddXR11dXVUV1eTmZnJc889R25uLtOnT6e4uDhkHaSoFvbm5mbef/99iouLGTlyJBkZGZw+fZqamhouvfRSpk+fTkpKCgcPHmTr1q3aW48yp9PJNddcw7/8y78QFxfHihUrWL9+fbTDGpKcTifTp0/niiuu4PTp0+zduxeHw9Fz/UdycjJXXnklXq+XPXv2kJKSQlZWFjNmzGD+/Pn89a9/5Y033tDiHkZtbW28/PLLrF27ljNnzpzz4Wl1dTVbt27l7rvvZtasWbz44os9w2jBivp0R4/H0/MqJiKICKNGjWLBggVkZmbS2trKli1bqKys1A/noqT7ArKZM2fyve99j7y8PN555x1++ctf0tzcHO3whqSMjAyuuuoq8vPzqamp4dZbb+Xaa6/t+brb7eaSSy7B4XCwYMECrr32WoYNG0ZWVhZut5uKigrWrFmjhT3MmpubP7ONdHZ2snHjRhYvXkx2djYpKSmxU9h7M8bgcrmYOXMmX/7yl3G73ZSUlLB582b9A4ySuLg4xowZw/z587nnnnuYOHEiu3fv5oknnugZJ9Tx9chzuVy43W7q6upwOp3Mnj2752siwrBhw3C5XDQ3N5Ofn09nZyeNjY2UlZVRXV3Nzp07tU1FmTGGuro6vF5vT6c2VCxV2EWEzMxMrrzySnJycvB4PGzevJmSkhLtrUdJXl4e//zP/8xtt93GRRddRGdnJ0ePHmX06NEMGzYMr9dLbW0t1dXVtLe309HRQVtbm16FGmY1NTW8+OKLfPzxx+csBetyufjGN75BYWEhH3zwAe+++y4NDQ2cOHGCuro6amtrqa2t1cIeZU6nk7y8POx2O8aYkHaQLFXY3W43l112GZdffjkJCQnU19fz6aef6odzUeRyuUhMTOxZHyYlJYW5c+dy6aWX9lxbUF1dzZEjR2hqauL06dOUl5dTVVVFaWkpJ0+e1BflMGhtbWXz5s1s3br1nJ7e2LFjufvuu+nq6uKtt97i2Wef7Vn2WlmD0+nkyiuvZMmSJRhjOHz4cEgXB7NUYU9MTGTSpEmMGjWKtrY2PvzwQ3bs2KF/kFF09OhRfv3rX/Pqq69y0UUXUVBQwPDhw3vWH3G73YwePZrJkyf3rM/e2NjIyZMn+d3vfseqVat0HD5MjDF9XqI+adIk8vPzqa6uZvv27fruyUKSkpLIz8/n0ksv5Z577mH69Ols2rSJ5557LmTj69CPwi4iecDzQBbgA54xxvxKRB4Bvg10T5z9YWCpywFrbW1l27ZtOBwOfD4f7733Hvv2hWSZ6pgV7vy0tLSwe/du9uzZg9PpJDExkfj4eJKSkrDZbLhcLrKzs8nNzSUtLY3CwkJGjx5NR0cHTU1NQ3rRqUi2nW42m41JkybhdrvZsmULZWVloThsTApnflwuF0VFRYwZM4aGhgY8Hg+ZmZnMnDmT6dOnM3bsWLKysti5cyePP/4427dvD2lb6U+P3QM8bIzZISLJwHYReTfwtV8YYx4PVTCtra2sW7eOrVu3YoyhpaVFpzieX9jz0z3+91mLgX388cfExcXhcDh61mU3xujyyhFsO91cLhcTJkxARCgtLQ1pLzAGhS0/I0aM4Bvf+AZf/epX6ezsxOfz4Xa7GTZsGADHjh3jvffe48UXX2TLli0hv3jsvIXdGHMCOBH4f5OIHMC/i3fIGWNobW3VD3UuQCTz81m6r6YDtJD0Eo3cdH/mcerUKTZt2jSk3zGdTzjz09jYSGlpKadOnSIxMRGAEydOsGHDBt5991127NjBiRMnenrzoSYX8kmsiOQDHwJFwEPAN4BGoAT/K985n3KKyFJgaeDu9KCi7SdjTOjmDQ0imh/rimRuRo0axahRo9i9e/dAXmi3G2O+dKE/NNiFOj/dKzump6fjdDoB/6ZBjY2NPbPGBjILpt9tp/tt9vluQBKwHbglcH8E/v0AbcCj+PcFPN8xTCRu/f2dYumm+bHuLRq5EZGB5qck2s/XUMhPuNtOv3rsIuIE3gLWGmP+q4+v5wNvGWOKznOcJiBcO+sOB2qB0caYzDCdw5I0P9YVwtzUAC34n8NQ684NaH7+8ev5DMK2059ZMQI8Cxzo/YuLSLbxj1EB3Ax83I/zlZowvc0TkZJwHdvKND/WFcrcGGMyw/UcDsXcQGy3nf7MirkCuBvYKyK7Ao/9EFgsIlPxv0U4Atx/ISdWIaP5sS7NjbXFbH76MytmE9DXgH1I5t2q4Gh+rEtzY22xnB9bhM/3zCA99lCh+bG2cD2HmpvgWartXNB0R6WUUtYX6R67UkqpMNPCrpRSMSZihV1EFopIqYiUiciyII+VJyLrReSAiOwTkX8NPP6IiFSJyK7A7brQRB/bNDfWpvmxLqvmJiJj7CJiBw4C84BKoBhYbIzZP8DjZQPZptfiPcBNwO1AswnD4kqxSnNjbZof67JybiLVY58JlCkBLq8AABduSURBVBljDhtjOoGXgUUDPZgx5oQxZkfg/01AxBe+iiGaG2vT/FiXZXMTqcKeC1T0ul9JiP6YApf8TgO2BR56QET2iMhKEUkLxTlinObG2jQ/1mXZ3ESqsPd1EUDQY0AikgS8DvybMaYReAoYB0zFvxznE8GeYwjQ3Fib5se6LJubSBX2SiCv1/2RwPFgDhhYvOd14I/GmDcAjDGnjDFeY4wPWIH/rZL6fJoba9P8WJdlcxOpwl4MFIjIGBGJA+4A/megB/u8xXt6fVt/F+8Z6jQ31qb5sS7L5iYim1kbYzwi8gCwFv86xyuNMcFsZhqzi/dEmubG2jQ/1mXl3OiSAkopFWP0ylOllIoxWtiVUirGaGFXSqkYo4VdKaVijBZ2pZSKMVrYlVIqxmhhV0qpGKOFXSmlYowWdqWUijFa2JVSKsZoYVdKqRijhV0ppWKMFnallIoxli3sIjJBRNaJSENgB/Cbox2T8hORfBFZLSL1InJSRH4jIhFZAlqdn7Yd6xKR5n+4eUXk16E+jyULe6BI/AV4C0gHlgIvisgXohqY6vYkUA1k49+u62rgn6IakQK07VidMSap+waMANqAV0N9HksWdmA8kAP8IrAl1DpgM/5F6FX0jQFeMca0G2NOAmuAiVGOSflp2xk8/hf+DtLGUB/YqoW9r01iBSiKdCCqT78C7hCRBBHJBb6Cv7ir6NO2M3h8HXjehGG3I6sW9k/wv5J9X0ScIjIf/9v9hOiGpQI24O+hN+Lf0LcEeDOqEalu2nYGAREZhT8vfwjH8S1Z2I0xXcBNwPXASeBh4BX8RURFkYjY8O/x+AaQCAwH0oCfRzMu5adtZ9C4B9hkjCkPx8EHzZ6nIrIF+IMx5r+jHctQJiLDgRog1RjTEHjsJuCnxhh9u29B2nasR0QOAsuNMSvDcXxL9tgBRGSyiMQHxnG/h38GxnNRDmvIM8bUAuXAd0XEISKp+McKd0c3MtVN2461icjlQC5hmA3TzbKFHf+n+CfwjxdeC8wzxnRENyQVcAuwEH/PvQzwAA9GNSLVm7Yda/s68IYxpilcJxg0QzFKKaX6x8o9dqWUUgMQVGEXkYUiUhq4bHlZqIJSoaH5sS7NjbUN9vwMeChGROzAQWAe/qlUxcBiY8z+0IWnBkrzY12aG2uLhfwE02OfCZQZYw4bYzqBl4FFoQlLhYDmx7o0N9Y26PMTzIp8uUBFr/uVwKX/+E0ishT/QkQA04M4X78ZY/q6rHqo0fxYl2VzA9QaYzIjdC6rsmx++tt2ginsfZ3gnHEdY8wzwDMAIvK54z5Op5P4+Hgcjr+H5fV6aWtro6urK4hQh6SQ56c3u91OWloa06dPJzk5GYCWlhZ27drFiRMnBhjykGHltnP0Qr45RoW17QyUzdb/AZZgCnslkNfr/kjg+EAPlpGRwaxZs7j88svJzMzEZrNhjKG+vp4NGzZQXFxMbW0tPp8viJCHlJDmp5vNZiMjI4PCwkKWLFnC7NmzOXPmDE6nk8TERFasWMFvf/tbvF5vsKeKZdp2rC0sbSeijDEDuuF/UTiMfwnXOPxXHk48z8+Yvm6pqanmu9/9rjlw4IBpamoyNTU15uTJk6ampsa0t7ebw4cPm+XLl5uxY8f2+fP/eBvo7xRLt1Dmp/tmt9vN1KlTzfLly83mzZvNli1bzMMPP2yKiorMnDlzzJo1a8yPf/xj43A4ND8Ryk2o2w5QEu3nJ9q3cLSdUNxsNpvp7+8w4B67McYjIg/gXxDKDqw0xuy70OPYbDamTZvGXXfdxUUXXcTatWspLi6mvb2d+Ph4ZsyYwTXXXMM3v/lNDh06RHl5efcTqT5HqPLTW15eHg8++CAFBQW8//77rFmzhl27dtHa2sq0adNwu93U1dVpfs5D2461hSo/IoLD4eh5B+X1evH5fBHJQVDbmRljVgOrgwrA4WD8+PHk5+dTXFzMY489xp49e/B4PNhsNsaMGcNjjz3GNddcQ2FhIQ6HQ8fb+ykU+emtqKiIiRMn8vTTT/Pqq6/S0NAAgMvl4oorrkBE2LZtmw7D9IO2HWsLNj8iwkUXXcSkSZNIT0+no6ODyspKampqOHPmzGe2EWMMHo+Hrq6uoF4Aor5PpYgQFxeH3W7n8OHDHDlyhPb29p6vl5WVsW/fPubOnYvb7UZkqE+oiJ6EhAQ6OjrYuXMnjY2NPY9nZ2czb948iouL+fjjj6MY4dCibce6HA4Hl1xyCd/61rfIy8vD4/FQXV1NbW0tlZWVdHZ2npWP7iGUlpYWDhw4wM6dO3s6TgM6fyh+iWAYY+js7MTr9TJ+/HgmT57Mzp07z3pV016GNTQ0NOB2u7nkkkvYs2cPXV1d2O125s2bR1ZWFo899hjNzc3RDnPI0LZjXcYYGhsbOXDgAMePHyc+Pp7s7GxmzJjB7NmzaW5uJikpCbvdjjGGrq4uRASn08n69eupqamhqalpwB94R72wd3V1sX//fg4fPsyXvvQlnnjiCcrKyti/fz8VFRU0NjYyatSoaIepgP3793Ps2DHuuecePvroI0pLS5k2bRr33nsvmzdvZufOndEOcUjRtmNdHo+HTz75hOrqamw2G06nk5SUFHJzc8nNzaWuro6cnBycTic+n4+uri4mTJjAokWLSE1NxW63B3X+qBd2YwwlJSX85je/4Tvf+Q5TpkyhsLCQ+fPn4/F48Hg8OJ1OfRtpAVVVVTz99NM8+uijLFu2jCeeeIJly5Zht9t54YUXaGlpiXaIQ4q2HWtraWmhtbW1577NZmP//v3Ex8fT2dlJfHw8NpsNESE7O5uxY8dSX1/fcy3IoB5jB/8T8Oc//5ni4mKKioq46qqrmDBhAvHx8eTn55OTk4PH46GxsVHn4kaRz+dj3bp1PP744yxfvpwpU6aQm5vLQw89xO7dus9GNGjbsbbexdnr9eL1ens+B2ltbUVESEhIoKCggKuuuoqysjI2b97MmTNnBn9hB+js7OTw4cOUl5ezevVqXC4XdrudsWPHsmLFCsaNG8eRI0fweDzRDnVI6+zs5M033yQzM5Of/vSntLS0UFFRoUUjirTtDF4iQm5uLgsWLCAjI4N169ZRUVERdK4stx5793SflpYWGhsbaW5uJj09Ha/Xe9ZMDBU9o0ePJisrCxEhMzOTRx99lMmTJ0c7rCFP287gk5SUxFVXXcU111zD7t27eeWVVzh16lTQc90tV9j/UUJCAvHx8TQ3N1NeHpYNvdUFmjVrFvfddx9JSUl8+OGHJCQk8PDDD5ORkRHt0FQv2nasb9iwYcyYMQOv18umTZsoLS2ls7Mz6ONavrAXFhaSmppKW1vbWR9EqOhZvXo1q1atoq2tjVWrVvHUU09x2WWXMWfOnGiHpnrRtmNtLpeLiy++mEsuuYSDBw+ybt26kE1AsHRhd7lcXHPNNTidTj755BOqqqqiHZICUlJSmDJlCtu3b+e9995j/fr1HD9+vOdCGBV92naszW63M27cOJYsWUJqaiobN27k008/DdnnIJYu7KNHj2b27Nl0dHSwZcsW6uvrox3SkOd0Orn11lvJzc3l5z//OeXl5Rw/fpwPPviA8ePHM2LEiGiHqNC2Y2Xdyw3cfvvtXHvttZSVlfHOO++E9OI+yxZ2h8PB9ddfz7hx46ioqODDDz/UmRcWkJ6ezoIFC9i6dSsbN27subhi3759JCQkkJWVFe0QhzxtO9aWnJzM9ddfz6233kpzczN//etfOXToUEjXWLJsYR87diyLFy/GbrezevVqXYPEItxuN2lpaWzatImmpibAP7/91KlTANpjtwBtO9blcDi4+OKLuffee0lNTeXtt9/mnXfeCfnFfZYs7HFxcSxatIiioiKqqqp47bXX9MMfixkzZgw5OTm4XC7i4uJISEjAZrPpXOko07ZjXTabjZEjR7J48WLy8/NZt24dL730ElVVVSF/R3XeC5REJA94HsgCfMAzxphficgjwLeBmsC3/jCw1GXQvvjFL3LnnXfidDp5++232bt3bygOG5MinZ+GhgaKi4u58cYbKSgooKysDK/Xy8SJE2lububQoUPBniJmaNuxtkjnJzExkTlz5rBo0SJsNhtr1qzh008/DctCbf258tQDPGyM2SEiycB2EXk38LVfGGMeD2VAIsK0adMYNWoUW7du5Xe/+52uQfL5IpqfhoYGli9fzty5c5k2bRr5+fkY49+G7aWXXtL50mfTtmNtEcuPw+GgoKCAW265hVGjRnH69GlqampCMme9z/Od7xuMMSeAE4H/N4nIAfy7eIeFMYZ3332Xrq4uXd+7HyKdH5/PR3l5Oc8//zyvvvpqz+bJPp+PlpYWOjo6wnXqQUfbjrVFMj9Op5PCwkLGjx+PMYZDhw4FvR7M57rAvQDzgWNACvAIcATYA6wE0j7jZ5YCJYFbv/b2ExHjdDpNYOfvC75Fc7/EaN4ilZ9gb9F+nmI5N8G2HYbonqfhzk9CQoJZsmSJ+dvf/mbeeecdM2/ePJOUlHRBebqQPU8lEOB5iUgSsAF41BjzhoiMAGoDJ/0JkG2Mufc8x4jIhovGmCG3Tqnmx7oGU26A7caYL0XoXJYQifzYbDbS0tIYMWIEnZ2dVFZWnrXbVX/YbDa8Xm+/2k6/CruIOIG3gLXGmP/q4+v5wFvGmKLzHKcJKO1PYAMwHH8yRhtjMsN0DkvS/FhXCHNTA7Tgfw5DrTs3oPn5x6/nMwjbTn9mxQjwLHCg9y8uItnGP0YFcDPQnwG90nD1BkSkZKj1NEDzY2WhzI0xJjNcz+FQzA3Edtvpz6yYK4C7gb0isivw2A+BxSIyFf/blSPA/RdyYhUymh/r0txYW8zmpz+zYjYBfY3rhGTerQqO5se6NDfWFsv5ifSVp88M0mMPFZofawvXc6i5CZ6l2k6/Z8UopZQaHCy5VoxSSqmB08KulFIxJmKFXUQWikipiJSJyLIgj5UnIutF5ICI7BORfw08/oiIVInIrsDtutBEH9s0N9am+bEuq+YmImPsImIHDgLzgEqgGFhsjNk/wONl478arGfxHuAm4Hag2YR4caVYprmxNs2PdVk5N5Hqsc8Eyowxh40xncDLwKKBHswYc8IYsyPw/yYgrIsrxTjNjbVpfqzLsrmJVGHPBSp63a8kRH9MgUt+pwHbAg89ICJ7RGSliKSF4hwxTnNjbZof67JsbiJV2Pu6CCDoMaDA4j2vA/9mjGkEngLGAVPxL8f5RLDnGAI0N9am+bEuy+YmUoW9EsjrdX8kcDyYAwYW73kd+KMx5g0AY8wpY4zXGOMDVuB/q6Q+n+bG2jQ/1mXZ3ESqsBcDBSIyRkTigDuA/xnowT5v8Z5e39bfxXuGOs2NtWl+rMuyuenPImBBM8Z4ROQBYC1gB1YaY/YFcciYXbwn0jQ31qb5sS4r50aXFFBKqRijV54qpVSM0cKulFIxRgu7UkrFGC3sSikVY7SwK6VUjNHCrpRSMUYLu1JKxRgt7EopFWO0sCulVIzRwq6UUjFGC7tSSsUYLexKKRVjtLArpVSMsWxhF5EXReSEiDSKyEER+Va0Y1JKqcHAssv2ishE/BvFdojIeOAD4HpjzPboRqaUUtZm2R67MWafMaaj+27gNi6KISml1KBg2cIOICJPikgr8An+TVxXRzkkpZSyPMsOxXQTETtwGTAH+Lkxpiu6ESmllLVZuscOENidexP+HcC/G+14lFLK6ixf2HtxoGPsSil1XpYs7CJykYjcISJJImIXkQXAYmBdtGNTSimrs+QYu4hkAq8BU/C/+BwF/j9jzIqoBqaUUoOAJQu7UkqpgbPkUIxSSqmB08KulFIxJqjCLiILRaRURMpEZFmoglJKKTVwAx5jD1w4dBCYB1QCxcBiY8z+0IWnlFLqQjmC+NmZ+BfpOgwgIi8Di4DPLOwiEpFPao0xEonzKKWUFQUzFJMLVPS6Xxl47CwislRESkSkJIhzKaWU6qdgeux99YrP6ZEbY54BnoEL67GLCHFxcSQkJOB0Onse7+rqorm5ma4uXTJGKaX6EkxhrwTyet0fCRwPLhyw2WwkJyeTl5fHlClTmDVrFllZWT1fr66u5rXXXmPLli10dHR8zpGUUmpoCqawFwMFIjIGqALuAO4c6MFEhPT0dMaPH8/s2bO54ooryM7O5ujRoxw8eBCv14vb7Wbq1KksXbqUqqoqDh48GET4SikVmwZc2I0xHhF5AFgL2IGVxph9AzmW0+lk7Nix3HTTTcyePRufz0dJSQl79uyhpKSE6upqfD4f8fHx3HDDDdx3333MmjWLo0ePaq9dKaX+QUSXFPisMfaioiLuv/9+Jk6cyLp161i9ejWffPIJra2t53xvfn4+P/jBD3A6nfzsZz+jrKzsnO/RWTFKqaEsmKGYkHE4HFRUVPDBBx+wYcMGTp8+zWe94Jw8eZK//e1v3HXXXRQWFnL48GF8Pl+EI1ZKKeuyRGEvLS3l2LFjtLS0nHdopb29nSNHjtDe3k5KSgo2m00Lu1JK9WKJwt7W1kZbW9s5j9tsNuLj48nIyMBut/c8lpWVhdPpxBjzmT17pZQaqixR2Huz2+1kZ2fz5S9/mQkTJjB+/Hjy8/NxuVw935OYmMiBAwd0GEYppfpgucI+adIkfvnLXzJ9+nRsNhudnZ1UV1fj8Xjo7OzkxIkTpKWlkZmZyZgxY9i7d2+fvX2llBqqLDErpresrCxuuOEGUlNTOXbsGMeOHaOyspLOzk68Xi/t7e2MGTOGH/zgB6Snp/OjH/2IHTt2nDUko7NilFJDmeUKe3/YbDbmz5/PsmXLePbZZ3nllVfO+tBVC7tSaigblBtt+Hw+Dh8+TH19Pbm5uWeNvyul1FA3KAs7QEtLC83NzdEOQymlLGfQFnan00lcXFy0w1BKKcuJ+qwYm81GSkoKxhi8Xm/PfPXP43K5mD59OiNGjKClpUWnPCqlVC9RL+zDhg3jq1/9Kjk5OXR1deFyuRD5/M8+k5OTmTx5MtXV1RQXF+t0R6WU6iXqhd3hcJCTk8OcOXNoa2vjzJkzeDyez/0Zr9fLli1bWLduHbt378br9UYoWqWUsr7zTncUkTzgeSAL8AHPGGN+JSKPAN8GagLf+kNjzOrzHOuckzmdTnJzc8nKyqK9vZ3GxsbzFmqv10tTUxNNTU19DsPodEel1FDWn8KeDWQbY3aISDKwHbgJuB1oNsY83u+T6WbWSikVducdijHGnABOBP7fJCIH6GPTaqWUUtZwQdMdRSQfmAZsCzz0gIjsEZGVIpIW4tiUUkoNQL8Lu4gkAa8D/2aMaQSeAsYBU/H36J/4jJ9bKiIlIlISgniVUkqdR7/WihERJ/AWsNYY8199fD0feMsYU3Se4+gYu1JKhdl5x9jFP6n8WeBA76IuItmB8XeAm4GP+3G+ZqB0IIH2w3CgFhgdpuMrpdSg0J9ZMbOBjcBe/NMdAX4ILMY/DGOAI8D9vQr9Zx2rxBjzpSBjjvixlVJqMOnPrJhNQF9DG587Z10ppVR0DNpFwJRSSvUt0oX9mUF6bKWUGjQiuoOSUkqp8NOhGKWUijFa2JVSKsZErLCLyEIRKRWRMhFZFuSx8kRkvYgcEJF9IvKvgccfEZEqEdkVuF0XmuiVUmrwiMgYu4jYgYPAPKASKAYWG2P2D/B4IVtxUimlYk2keuwzgTJjzGFjTCfwMrBooAczxpwwxuwI/L8J0BUnlVIqIFKFPReo6HW/khAVYl1xUimlzhapwt7XlatBjwENdMVJpZSKZZEq7JVAXq/7I4HjwRwwsOLk68AfjTFvABhjThljvMYYH7AC/xCQUkoNKZEq7MVAgYiMEZE44A7gfwZ6sM9bcbLXt/V3xUmllIop510ELBSMMR4ReQBYC9iBlcaYfUEc8grgbmCviOwKPPZDYLGInLXiZBDnUEqpQUmXFFBKqRijV54qpVSM0cKulFIxRgu7UkrFGC3sSikVY7SwK6VUjNHCrpRSMUYLu1JKxZj/H/CM3Kw3LPOzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = CNN().to(device)\n",
    "model.load_state_dict(torch.load('mnist_model.pth', map_location = device))\n",
    "model.eval()\n",
    "n_image = len(digit_files)\n",
    "ncols = 4\n",
    "nrows = np.int(np.ceil(n_image/ncols))\n",
    "\n",
    "for i, (x,f) in enumerate(my_test_dataloader):\n",
    "    x = x.to(device)\n",
    "    _,pred = model(x).max(-1)\n",
    "    plt.subplot(nrows,ncols,i+1)\n",
    "    plt.imshow(x[0,0].to('cpu').numpy(),cmap='gray')\n",
    "    plt.title(pred[0].item())\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict a sigle image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,img):\n",
    "    model.eval()\n",
    "    \n",
    "    if type(model) is CNN:\n",
    "        img_tensor = transform_test(img).unsqueeze(0).to(device) # (1,28,28)\n",
    "    else:\n",
    "        img_tensor = transform_test(img).reshape(-1, 28*28).to(device) # (1,28,28)\n",
    "\n",
    "    _,pred = model(img_tensor).max(-1)\n",
    "    return pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAYAAABw4pVUAAAFN0lEQVR4nO2dL3DyPBjAn/e7747KysjOZS6OSmRlcZsDxxxybqCQ4LapbQqmwHFTMAVT4Ipbp8bUmGpdXvF93A02aChNk7T53cUAbR/6I38a0qd/AICCRhr+ER2AZhMtRDK0EMnQQiRDC5EMLUQytBDJ0EIkQwuRDC1EMrQQyfhXdADHgjEG27bBsqyN133fh/l8DvP5XEhccVFGyG8nvlgsguM4e7ebTqdQrVZhsVhwjjAZ/oCks72EECCEgGVZTCd+H4vFAsrlsjJSqEwFY0yHwyFNGs/zKMZY+PdjKMIDoABACSFcRGxLMQxD+HeVWgivGrEL13VFn/C9RdiwF2MMw+EQPM87qn84FEJIaseKS6q/AIRQqjViGwWarfQOZts2fX195XKigyCg7Xabvr+/R3727OxM9EnfWVK5DjFNE7rdbiJNUxiGcHNzA19fXxuv93o9WCwW8PLyAt1ud+8+MMZHx8GLVIT0+30olUqxt/8uYX3idzEYDMD3/R9X7qrAXYht27FkrCW8vb1Br9eD5XLJvN3DwwNcXV0dfEwZSEXIoYRhCNVqFXq9HoeI5Ia7EMMwmD4Xt0ZkDe5CWGZbO50O3N7eKjPXxBPuQsbj8c5ONgxDuLi4gPv7e95hKAP3K/UwDOH8/PxHE7TuJ7SMTVIZ9k6nUzg9PYVKpQKmacJqtcp1P7GP1P6gWq1W0Ol00jqcsuj/1CUjk0KKxaLoEGKTOSGEkFSn85Mmc0JarVbkZ1arFf9AjkD4lHNShRDCNE1vWZbwWHeVTNUQlknMZrMJvu9zj+UYhP8qkiqz2Uzp2vF/ER5AIsV13cjmql6vC48zN0KiagelVK/LSquw1I5+vy88ztwIYakdhBDhceZCSKlUylLtUF/I9fV1lmqH2kIQQpHrsBSrHWoLmUwmWasd6gq5vLyMlOF5nvA4cyEEY0yDIIgU0mg0hMeaCyEsTdXn5ydFCAmPNfNCWIa5lMq9oDpTQliGuYo2VWoKiRrmzmYz2e//yI4QlpGVgsNcNYWwjKwUHeZuFCX+MUQIwXA4jFy4/fj4mFJEfBH+q4gqLMPcIAhUHeZuF+EB7C0s/Qalyo+s1BDCekWegZGV/EIsy2K6YzcIgiyMrOQWghBivn26UqkIjzfzQkajEZOMDPUb8gphWbBAaeb6DTmF5LjfkE/IIWk3MthvyCPENM2DktFkXIZYIQghpqvwNQouWFBHiOu6B2UGCoJAlaWgagmJmy8rB01VukIwxrRSqcTKl5UjGfyFHJtBLmcy+Ao5ZApkmyAI8iiDck2k3G63oV6vx9p2Op3C09MTAPyXNtz3fRiPx8kFJynchFiWBZ7nMadnYmU8HsPz8/PO97Mgj0vVY10/xZPRaEQbjQa1bVt4U8RauNUQQgjMZjMeu47FcrmEwWAAHx8fP96T6UkK3IQYhgGTyUSJxMVr1v2WSEFcO3XLsmAymQBCiNchuPJ9YAGQTk3i/rgK0zTBcZxfc+UWCgVwXVfqPLq/wfuZJMI7Mowxvbu7Ez0GOAheKculeqCLZVngOM5GE1coFKBUKsVKN8ubcrkMg8Eg0X1KJWQfhmFEiklbXrPZhEajkfh+hTdZSRfDMKjjOLTValHP87g1WzymdpSpIceAMQbXdX/MGhQKBajVamCa5sH7DMMQTk5OEk/kmQsh+0AIQa1WAwB2QTxToedeyDbfBf0G7xS3WohkKHF/SJ7QQiRDC5EMLUQytBDJ0EIkQwuRDC1EMrQQydBCJEMLkQwtRDK0EMnQQiTjLz9nccx1fFbnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=100x100 at 0x25B1184D160>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#path = 'seven2.png'\n",
    "#path = 'eight.png'\n",
    "#path = 'seven.png'\n",
    "#path = 'three.png'\n",
    "#path = 'five.png'\n",
    "#path = 'my_digit4.png'\n",
    "path = 'my_digit2.png'\n",
    "#path = 'mnist_digit.png'\n",
    "# img = Image.open(path).convert('L').resize((28, 28))\n",
    "# img_tensor = transform(img).reshape(-1,28*28)\n",
    "\n",
    "\n",
    "img = Image.open(path)\n",
    "#img = Image.fromarray(drawing_image)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-16.1592,  -0.1211,  53.6910,   5.0860, -25.4025, -48.2006, -34.3265,\n",
       "           6.1174,  -1.5220, -17.2006]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if type(model) is CNN:\n",
    "    img_tensor = transform_test(img).unsqueeze(0).to(device) # (1,28,28)\n",
    "else:\n",
    "    img_tensor = transform_test(img).reshape(-1, 28*28).to(device) # (1,28,28)\n",
    "\n",
    "\n",
    "model(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 흑백으로 (28,28)로 resize된 이미지로 저장하기\n",
    "tr = transforms.Grayscale(num_output_channels=1)(img)\n",
    "tr = transforms.Resize((28,28))(tr)\n",
    "temp = np.array(tr).astype(np.uint8)  #, img_tensor.shape\n",
    "print(temp.dtype)\n",
    "np.savetxt('mnist_digit.txt',temp,fmt='%i')\n",
    "im = Image.fromarray(temp)\n",
    "im.save(\"resized_mnist_fig.png\")\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import ctypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:  4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating a 600 x 600 pixels canvas for mouse drawing\n",
    "canvas = np.ones((600,600), dtype=\"uint8\") * 255\n",
    "# designating a 400 x 400 pixels point of interest on which digits will be drawn\n",
    "canvas[100:500,100:500] = 0\n",
    "\n",
    "start_point = None\n",
    "end_point = None\n",
    "is_drawing = False\n",
    "\n",
    "def draw_line(img,start_at,end_at):\n",
    "    cv2.line(img,start_at,end_at,255,15)\n",
    "\n",
    "def on_mouse_events(event,x,y,flags,params):\n",
    "    global start_point\n",
    "    global end_point\n",
    "    global canvas\n",
    "    global is_drawing\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        if is_drawing == False:\n",
    "            is_drawing=True\n",
    "            start_point = (x,y)\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if is_drawing:\n",
    "            end_point = (x,y)\n",
    "            draw_line(canvas,start_point,end_point)\n",
    "            start_point = end_point\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        is_drawing = False\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"Test Canvas\")\n",
    "cv2.setMouseCallback(\"Test Canvas\", on_mouse_events)\n",
    "\n",
    "\n",
    "while(True):\n",
    "    cv2.imshow(\"Test Canvas\", canvas)\n",
    "    key = cv2.waitKey(1) & 0xFF \n",
    "    if key == ord('c'):\n",
    "        canvas[100:500,100:500] = 0\n",
    "    elif key == ord('d'):\n",
    "        drawing_image = canvas[100:500,100:500]\n",
    "        break\n",
    "        #result = net.predict(image)\n",
    "        #print(\"PREDICTION : \",result)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "plt.imshow(drawing_image,cmap='gray')\n",
    "\n",
    "draw_image=Image.fromarray(drawing_image)\n",
    "pred = predict(model,draw_image).item()\n",
    "\n",
    "ctypes.windll.user32.MessageBoxW(0, str(pred), \"Prediction\", 0)\n",
    "print('prediction: ', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing2: 이미지를 입력받아 파일로 저장(clear후 반복 저장 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageTk, Image, ImageDraw\n",
    "import PIL\n",
    "from tkinter import *\n",
    "import os\n",
    "width = 200\n",
    "height = 200\n",
    "center = height//2\n",
    "white = (255, 255, 255)\n",
    "black = (0,0,0)\n",
    "green = (0,128,0)\n",
    "\n",
    "def save():\n",
    "    j=0\n",
    "    filename = \"image\" + str(j) + \".png\"\n",
    "    \n",
    "    while os.path.exists(filename):\n",
    "        j += 1\n",
    "        filename = \"image\" + str(j) + \".png\"\n",
    "    image1.save(filename)\n",
    "\n",
    "def clear():\n",
    "    cv.delete(\"all\")\n",
    "    global image1, draw\n",
    "    image1 = PIL.Image.new(\"RGB\", (width, height), black)  # 저장되는 backgroudn color\n",
    "    draw = ImageDraw.Draw(image1)\n",
    "    \n",
    "    \n",
    "\n",
    "def paint(event):\n",
    "    x1, y1 = (event.x - 1), (event.y - 1)\n",
    "    x2, y2 = (event.x + 1), (event.y + 1)\n",
    "    cv.create_oval(x1, y1, x2, y2, fill=\"white\",width=20)  # 저장되는 color\n",
    "    draw.line([x1, y1, x2, y2],fill=\"white\",width=20)\n",
    "\n",
    "root = Tk()\n",
    "\n",
    "# Tkinter create a canvas to draw on\n",
    "cv = Canvas(root, width=width, height=height, bg='white')\n",
    "cv.pack()\n",
    "\n",
    "\n",
    "image1 = PIL.Image.new(\"RGB\", (width, height), black)  # 저장되는 backgroudn color\n",
    "draw = ImageDraw.Draw(image1)\n",
    "\n",
    "\n",
    "\n",
    "cv.pack(expand=YES, fill=BOTH)\n",
    "cv.bind(\"<B1-Motion>\", paint)\n",
    "\n",
    "button1=Button(text=\"save\",command=save, width=10, height=2)\n",
    "button2=Button(text=\"clear\",command=clear, width=10, height=2)\n",
    "button1.pack(side='left',anchor='s')  # left --> south ---> 왼쪽 아래\n",
    "button2.pack(side='right',anchor='s') # 오른쪽 아래.\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMiwbDulbLWIZVOkveQbovi",
   "collapsed_sections": [],
   "name": "MNIST_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
